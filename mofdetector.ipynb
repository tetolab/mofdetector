{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io as spio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from data import get_training_data, get_test_data\n",
    "tfe = tf.contrib.eager # Shorthand for some symbols\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emnist\n",
    "see https://arxiv.org/pdf/1702.05373v1.pdf for breakdown of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load balanced letters dataset from csv\n",
    "df_train = pd.read_csv(\"data/emnist-letters-train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Shape\n",
    "data shape of df_train is:\n",
    "\n",
    "column 0 is the class\n",
    "\n",
    "columns 1 to 785 are the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels from first column\n",
    "df_train_y = df_train.iloc[:,[0]]\n",
    "# get 1d image data from other 784 columns\n",
    "df_train_x = df_train.iloc[:, 1:785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class transform\n",
    "By default the Y classes are made up of 26 numbers each representing a letter of the alphabet,\n",
    "as we only care about the characters 'm' and 'f', we will use a piecewise function to set anything that is not 'm' or 'f' to 0,\n",
    "any class that is 'f' to 1, and any class that is 'm' to 2.\n",
    "\n",
    "| class | mapping |\n",
    "|-------|---------|\n",
    "|   0   | unknown |\n",
    "|   1   |    f    |\n",
    "|   2   |    m    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(df_train_y)\n",
    "train_y = np.piecewise(y, [(y != 6) & (y != 13), y == 6, y == 13], [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Data Transform\n",
    "The training examples are 1d (1x784) and need to be resized to 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df_train_x.values.reshape((88799, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the images need to be rotated 90 degrees, the 0th axis of our train_x is the image index itself, thus we only want to rotate axis 1 and 2 as they are the actual image data\n",
    "\n",
    "The rot90 function is able to rotate an entire numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.fliplr(train_x)\n",
    "train_x = np.rot90(train_x, axes=(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot F's and M's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(28, 28))\n",
    "columns = 4\n",
    "rows = 2\n",
    "image_index = 0\n",
    "for i in range(1, columns * rows + 1):\n",
    "    figure.add_subplot(rows, columns, i)\n",
    "    while train_y[image_index] == 0:\n",
    "        image_index += 1\n",
    "    print(image_index)\n",
    "    plt.imshow(train_x[image_index], cmap='gray')\n",
    "    image_index +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Tensorflow model\n",
    "The model is created similiar to the example given at https://www.tensorflow.org/guide/eager\n",
    "\n",
    "The network is made up of several convolutional layers with maxpool layers inbetween"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOFCnn(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MOFCnn, self).__init__()\n",
    "        # CNN layers\n",
    "        self.cnn1 = tf.keras.layers.Conv2D(32, 3, input_shape=(28, 28, 1), activation='relu')\n",
    "        self.cnn2 = tf.keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.cnn3 = tf.keras.layers.Conv2D(128, 3, activation='relu')\n",
    "        \n",
    "        # maxpool layers:\n",
    "        self.maxpool = tf.layers.MaxPooling2D((2, 2), (2,2))\n",
    "        \n",
    "        # flatten layer:\n",
    "        self.flatten = tf.layers.Flatten()\n",
    "        \n",
    "        # fully connected layers\n",
    "        self.dense1 = tf.layers.Dense(100, activation='relu')\n",
    "        self.denseOutput = tf.layers.Dense(3, activation='softmax')\n",
    "        \n",
    "        # dropout\n",
    "        self.dropoutFull = tf.layers.Dropout(0.5)\n",
    "        self.dropoutHalf = tf.layers.Dropout(0.25)\n",
    "    \n",
    "    def call(self, input):\n",
    "        result = self.cnn1(input)\n",
    "        result = self.maxpool(result)\n",
    "        result = self.cnn2(result)\n",
    "        result = self.maxpool(result)\n",
    "        result = self.cnn3(result)\n",
    "        result = self.maxpool(result)\n",
    "        result = self.flatten(result)\n",
    "        result = self.dense1(result)\n",
    "        result = self.dropoutFull(result)\n",
    "        result = self.denseOutput(result)\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss(model, x, y):\n",
    "        prediction = model(x)\n",
    "        return tf.losses.softmax_cross_entropy(onehot_labels=y, logits=prediction)\n",
    "    \n",
    "    @staticmethod\n",
    "    def grad(model, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = MOFCnn.loss(model, inputs, targets)\n",
    "        return tape.gradient(loss_value, model.variables)\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(predictions, labels):\n",
    "        model_pred = tf.argmax(predictions, axis=1,output_type=tf.int64)\n",
    "        actual_labels = tf.argmax(labels, axis=1, output_type=tf.int64)\n",
    "        return tf.reduce_sum(tf.cast(tf.equal(model_pred, actual_labels),dtype=tf.float32)) / float(predictions.shape[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainMofCnn(model, x, y, batch_size, number_of_epochs):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    x = tf.data.Dataset.from_tensor_slices(x)\n",
    "    y = tf.data.Dataset.from_tensor_slices(y)\n",
    "    data = tf.data.Dataset.zip((x, y)).batch(batch_size)\n",
    "    for _ in range(number_of_epochs):\n",
    "        for xs, ys in data:\n",
    "            clear_output(True)\n",
    "            grads = MOFCnn.grad(model, xs, ys)\n",
    "            optimizer.apply_gradients(zip(grads, model.variables))\n",
    "            loss = MOFCnn.loss(model, xs, ys)\n",
    "            predictions = model(xs)\n",
    "            print(\"loss: {:.3f}\".format(loss))\n",
    "            print(ys)\n",
    "            #print(tf.contrib.metrics.accuracy(predictions, ys))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = get_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MOFCnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMofCnn(model, train_x, train_y, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.argmax(model(train_x[0:50]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model([train_x[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "nteract-on-jupyter@1.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
