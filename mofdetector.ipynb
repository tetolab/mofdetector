{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io as spio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "tfe = tf.contrib.eager # Shorthand for some symbols\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emnist\n",
    "see https://arxiv.org/pdf/1702.05373v1.pdf for breakdown of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load balanced letters dataset from csv\n",
    "df_train = pd.read_csv(\"data/emnist-letters-train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Shape\n",
    "data shape of df_train is:\n",
    "\n",
    "column 0 is the class\n",
    "\n",
    "columns 1 to 785 are the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels from first column\n",
    "df_train_y = df_train.iloc[:,[0]]\n",
    "# get 1d image data from other 784 columns\n",
    "df_train_x = df_train.iloc[:, 1:785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   23\n",
       "0   7\n",
       "1  16\n",
       "2  15\n",
       "3  23\n",
       "4  17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class transform\n",
    "By default the Y classes are made up of 26 numbers each representing a letter of the alphabet,\n",
    "as we only care about the characters 'm' and 'f', we will use a piecewise function to set anything that is not 'm' or 'f' to 0,\n",
    "any class that is 'f' to 1, and any class that is 'm' to 2.\n",
    "\n",
    "| class | mapping |\n",
    "|-------|---------|\n",
    "|   0   | unknown |\n",
    "|   1   |    f    |\n",
    "|   2   |    m    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(df_train_y)\n",
    "train_y = np.piecewise(y, [(y != 6) & (y != 13), y == 6, y == 13], [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.406</th>\n",
       "      <th>0.407</th>\n",
       "      <th>0.408</th>\n",
       "      <th>0.409</th>\n",
       "      <th>0.410</th>\n",
       "      <th>0.411</th>\n",
       "      <th>0.412</th>\n",
       "      <th>0.413</th>\n",
       "      <th>0.414</th>\n",
       "      <th>0.415</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...    0.406  0.407  0.408  \\\n",
       "0  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "1  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "2  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "3  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "4  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "\n",
       "   0.409  0.410  0.411  0.412  0.413  0.414  0.415  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Data Transform\n",
    "The training examples are 1d (1x784) and need to be resized to 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df_train_x.values.reshape((88799, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the images need to be rotated 90 degrees, the 0th axis of our train_x is the image index itself, thus we only want to rotate axis 1 and 2 as they are the actual image data\n",
    "\n",
    "The rot90 function is able to rotate an entire numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.fliplr(train_x)\n",
    "train_x = np.rot90(train_x, axes=(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot F's and M's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "50\n",
      "51\n",
      "65\n",
      "74\n",
      "99\n",
      "126\n",
      "129\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkAAAAS0CAYAAAA4kMSBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3X+QXnV9L/DPd7MxID8CgYShSEAsYy8gUpuhFGlKVRwNCNoZ8Tql2k5bOo5pS+eOgO20V6tWqre9LQMt0NYRgQtaLUUQqNqp4UepU0DKD7kURH6aISSb8KPimt393j9YhsgNJp/Nc/Ls8z2v1wyT5Mn77Pkenuz5PGffe54ttdYAAAAAAABoydiwFwAAAAAAADBoChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA54ztzZ6WUujP3B9Cw9bXWpcNexHxhvgAMRq21DHsN84XZAjAwrl22YL4ADMb2Xru4AwRgND087AUAAABsB9cuAAyNAgQAAAAAAGjODhUgpZS3lVLuK6U8UEo5e1CLAqDfzBcABs1sAaAL5gvA/DbnAqSUsiAizo+It0fEYRHx3lLKYYNaGAD9ZL4AMGhmCwBdMF8A5r8duQPk6Ih4oNb6YK31hxFxRUScMphlAdBj5gsAg2a2ANAF8wVgntuRAuSAiHh0iz8/NvvYjyilnF5KubWUcusO7AuA/jBfABg0swWALpgvAPPc+A5sW7byWP3/Hqj1ooi4KCKilPL//T0AvIT5AsCgmS0AdMF8AZjnduQOkMci4sAt/vyqiPjeji0HAMwXAAbObAGgC+YLwDy3IwXIv0fEoaWUV5dSXhER/z0ivjyYZQHQY+YLAINmtgDQBfMFYJ6b81tg1VqnSimrI+KfImJBRHym1nrPwFYGQC+ZLwAMmtkCQBfMF4D5r9S689560PscAgzMbbXWFcNexHxhvgAMRq11a+9l3ktmC8DAuHbZgvkCMBjbe+2yIz8EHQCAETU+3v3LwJmZmU7zAADA6Bkb25GfyrB9XFvwgu7/tQEAAAAAAOxkChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA5ChAAAAAAAKA548NeAABAH5RSUvl99tknlV++fHkqf+KJJ6byc3HTTTel8jfffHMqPzMzk8rPR1NTU8NeAgAA/IiFCxem8ieffHIqf+qpp6byCxYsSOUjIr7zne+k8pdcckkqf//996fyk5OTqTyD4w4QAAAAAACgOQoQAAAAAACgOQoQAAAAAACgOQoQAAAAAACgOQoQAAAAAACgOQoQAAAAAACgOQoQAAAAAACgOQoQAAAAAACgOQoQAAAAAACgOQoQAAAAAACgOQoQAAAAAACgOePDXgAAwChasGBBKn/22Wen8r/2a7+Wyi9fvjyVHx/v/mXgxMREKr9hw4aOVrJzbNq0Kb3Nxz72sVT+2muvTeVnZmZSeQAA2jM2lvse+AMPPDCVP/fcc1P5ZcuWpfKllFQ+Iv86+LjjjkvlL7roolT+P/7jP1L5Rx55JJXPXnv1iTtAAAAAAACA5ihAAAAAAACA5ihAAAAAAACA5ihAAAAAAACA5ihAAAAAAACA5ihAAAAAAACA5ihAAAAAAACA5ihAAAAAAACA5ihAAAAAAACA5ihAAAAAAACA5ihAAAAAAACA5ihAAAAAAACA5owPewEAAPPBwoULU/nDDjsslV+9enUqv99++6XyWdPT0+ltFixYkMovWbKk0/x88+yzz6a3ec1rXpPKl1LS+wAAoC1jY7nvaf/0pz+dyh911FGp/P7775/KZz355JPpbTZt2pTK77vvvqn8Oeeck8rvueeeqfwnP/nJVD67nqmpqVR+lLkDBAAAAAAAaI4CBAAAAAAAaI4CBAAAAAAAaI4CBAAAAAAAaI4CBAAAAAAAaI4CBAAAAAAAaI4CBAAAAAAAaI4CBAAAAAAAaI4CBAAAAAAAaI4CBAAAAAAAaI4CBAAAAAAAaM74sBcAANCFUkoqf9hhh6Xy5513Xiq/bNmyVH56ejqVf/jhh1P5q6++OpWPiHjHO96Ryh944IGpfPY5y9q8eXMq/8QTT6Ty3/jGN1L5iIirrroqlc/+u6AdS5YsSW+zxx57pPLf+973Uvns5xQAsHXZ18HZa4tTTjkllT/44INT+ayHHnoolT/zzDPT+7jrrrvS22Rkrx+PPPLIVP7RRx9N5WutqXyfuAMEAAAAAABozg7dAVJKeSginomI6YiYqrWuGMSiAOg38wWALpgvAAya2QIwvw3iLbB+sda6fgAfBwC2ZL4A0AXzBYBBM1sA5ilvgQUAAAAAADRnRwuQGhFfLaXcVko5fRALAoAwXwDohvkCwKCZLQDz2I6+BdYba63fK6Usi4ivlVL+b631hi0Dsyd/AwCADPMFgC782PlitgAwB65dAOaxHboDpNb6vdlf10XElRFx9FYyF9VaV/ghUABsL/MFgC5sa76YLQBkuXYBmN/mXICUUnYrpezxwu8j4q0RcfegFgZAP5kvAHTBfAFg0MwWgPlvR94Ca7+IuLKU8sLH+T+11usHsioA+sx8AaAL5gsAg2a2AMxzcy5Aaq0PRsTrB7gWADBfAOiE+QLAoJktAPPfDv0MEAAAAAAAgPmo1Fp33s5K2Xk7A2jbbX6A3ovMl/YtWrQovc0v/dIvpfJ//Md/nMq/+tWvTuW/+93vpvKXXHJJKn/hhRem8uvWrUvlIyL22WefVH6vvfZK76NLU1NTqfwTTzyRyk9OTqbyEREzMzPpbbpUay3DXsN8Md9my+rVq9PbnHzyyan8hz70oVT+zjvvTOV35rUnMK+4dtnCfJsvzA+HHHJIKn/FFVek8itWdPsp+MADD6Ty2dccV111VSrfgtm31ttufXydtb3XLu4AAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmjM+7AUAAP1TSknlV6xYkd7HmWeemcq/+tWvTuW///3vp/K/+Zu/mcrfddddqfyGDRtS+blYv359p3ng5S1dujS9zTHHHJPKn3HGGan8hz70oVR+YmIilR8b6/b79aampjr9+ACwvd7whjek8gcddFBHK3ne5ORkKv/Rj340lf+nf/qnVL6Paq3DXkIz3AECAAAAAAA0RwECAAAAAAA0RwECAAAAAAA0RwECAAAAAAA0RwECAAAAAAA0RwECAAAAAAA0RwECAAAAAAA0RwECAAAAAAA0RwECAAAAAAA0RwECAAAAAAA0RwECAAAAAAA0Z3zYC2hdKSWVP/bYY1P5e++9N5WfmJhI5WEUjI3lutzs52VExPT0dHob6JPs59UhhxySyp933nmpfETEYYcdlspv3Lgxlb/gggtS+VtuuSWVn5ycTOWB0TI+nrsUW7VqVXofu+++eyr/jne8I5V/5plnUvmf+ImfSOUPP/zwVP7ZZ59N5c8555xUPiLixhtvTOWffPLJVL7WmsoD0L3s1xx+4Rd+Ib2PT33qU6n80qVLU/ns1zSuueaaVP6KK65I5X2NhZ3JHSAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzxoe9gNbts88+qfynP/3pVP7CCy9M5T/3uc+l8rXWVL6Pdtlll1R+eno6ld+8eXMq34Jdd901lX/b296Wyi9fvjyVj4i44IILUvnJycn0PmCUHXTQQan85Zdfnsq//vWvT+Uj8p+H11xzTSr/l3/5l6m88wKwI/bcc8/O97FkyZJU/gMf+EAqX0pJ5cfGct+vl712Of/881P5iIjrrrsulf/4xz+eyj/44IOpvOs1gO5l59Fxxx2X3sfBBx+c3ibju9/9bip/6aWXpvLZr3XBzuQOEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDnjw15A644//vhU/uijj07lf+qnfiqV//rXv57KP/7446n8zrBgwYJUfsmSJan8qlWrUvnf/u3fTuXPPffcVP5zn/tcKj8XpZRU/qCDDkrl3/e+93Waz65nLh555JFU/sorr+xoJTA/LVq0KJVfvHhxRyt50X333ZfK/8Vf/EUqv2HDhlQeYEvZ11/zUfYYsq+nNm/enMovXLgwlZ/La8hTTz01vU3GWWedlcqvW7euo5UA8ILly5en8itWrOhoJS9av359Kp/9Wtd3vvOdVB7mM3eAAAAAAAAAzVGAAAAAAAAAzdlmAVJK+UwpZV0p5e4tHltSSvlaKeX+2V/37naZALTGfAGgC+YLAINmtgCMru25A+SzEfG2lzx2dkT8c6310Ij459k/A0DGZ8N8AWDwPhvmCwCD9dkwWwBG0jYLkFrrDREx8ZKHT4mIi2d/f3FEvHPA6wKgceYLAF0wXwAYNLMFYHSNz3G7/WqtayMiaq1rSynLXi5YSjk9Ik6f434A6BfzBYAubNd8MVsASHDtAjAC5lqAbLda60URcVFERCmldr0/APrBfAFg0MwWALpgvgAMz/b8DJCteaKUsn9ExOyv6wa3JAB6zHwBoAvmCwCDZrYAjIC5FiBfjoj3z/7+/RFx1WCWA0DPmS8AdMF8AWDQzBaAEbDNAqSUcnlE3BIRry2lPFZK+fWIOCciTiil3B8RJ8z+GQC2m/kCQBfMFwAGzWwBGF3b/Bkgtdb3vsxfvXnAawGgR8wXALpgvgAwaGYLwOia61tgAQAAAAAAzFvbvAOEH7Vo0aJU/pd/+ZdT+bGxXCc1MTHRaX5nKKWk8ieddFIqn30Ojj/++FR+n332SeVXr16dyl9xxRWpfETEnnvumcr/zM/8TCr/vve9L5U/+eSTU/nnnnsulZ+amkrls5/HERHHHntsKn/llVem9wHzSfbz5Jhjjknl995771Q++3keEfG1r30tlf/P//zPVL7WmsoDbGmvvfbqND8XMzMzqfyaNWtS+TPPPDOVf+qpp1L57P+ja665JpWPiFi2bFkq//a3vz2Vz67pS1/6Uirftey1XYR5Csx/p5xySir/pje9qaOVvGjjxo2p/MMPP5zKOzfTEneAAAAAAAAAzVGAAAAAAAAAzVGAAAAAAAAAzVGAAAAAAAAAzVGAAAAAAAAAzVGAAAAAAAAAzVGAAAAAAAAAzVGAAAAAAAAAzVGAAAAAAAAAzVGAAAAAAAAAzVGAAAAAAAAAzRkf9gKGaZdddklv8573vCeVP+mkk1L59evXp/If+9jHUvnnnnsulV+wYEEqv2TJklQ+IuLEE09M5c8///xUftddd03ls0opqfzrXve6VD57vBERv/iLv5jKH3DAAan8pk2bUvnrr78+lT/77LNT+dWrV3eaj8h/Ln/4wx9O5aemplJ56NqqVatS+T/90z9N5ffdd99U/sEHH0zlIyIuv/zyVD47IwG2NDaW+96y4447LpXfZ599Uvm52LBhQyp/3nnnpfK33XZbKt+1s846K73Npz/96VR+2bJlqfynPvWpVP7RRx9N5bOv+4844ohU/pBDDknlI/LXwM8++2wqPzMzk8pfeeWVqfx9992Xym/evDmVB4Zvzz33TOUXLVrU0UpelD231Vo7WgnMf+4AAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmqMAAQAAAAAAmjM+7AUM0wc/+MH0Nh/5yEdS+bGxXMd0zTXXpPLXX399Kn/kkUem8n/4h3+Yyv/8z/98Kh8Rse+++6by2f+npZRUvtbaaX7hwoWp/EknnZTKR0TcdNNNqfx73vOeVP6RRx5J5ScmJlL57HOW/Xe3YMGCVD4i4p577knlZ2Zm0vuA+eTYY49N5ZcsWdLRSp53++23p7d59NFHO1gJwNZlX6MeccQRnX78udi4cWMqn319NN/ceOON6W2yr4Oz1zoHH3xwKn/FFVek8rvttlsqv9dee6Xyc/l3mr2e6vrjv/Wtb03lzz777FT+1ltvTeUnJydTeWA0ZT/X/+3f/i2V9zUK+swdIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHPGh72AQdpll11S+ZUrV6b3seuuu6byExMTqfwVV1yRymeP4Q/+4A9S+cMPPzyVHxvLd2pPPfVUKr948eL0Prr0gx/8IJW/9tprU/nLLrsslY+IuPnmm1P5devWpffRpaVLl6byBx54YEcredEtt9ySys/MzHS0EpibV77ylan8CSeckMqPj+deUmQ/R77whS+k8hH5GQywM83ldXNW9lx79913p/IbN25M5eebtWvXprf5xje+kcofeeSRqXx2nh588MGpfPbfxOTkZCr/2GOPpfJzsddee6XyS5YsSeWPPvroVP68885L5f/oj/4olb/66qtTeWDw9thjj873kf1a0VlnnZXK+xoFfeYOEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDkKEAAAAAAAoDnjw17AIJ155pmp/EknnZTeRykllV+8eHEq/4//+I+p/Cte8YpUfnJyMpW/6qqrUvlbbrkllY+I+OIXv5jKX3nllan8/vvvn8pfcMEFqXx2Pffcc08qPz09ncq3YPny5an83nvvncpPTU2l8hER11xzTXob6NKCBQtS+RNOOCGVf+1rX5vKZ2XPbXfeeWfn+5hvxsZy36eSze8McznfAoMzMzOTymdfp27atCmVn282b96c3uaZZ57pYCUvyl5vZs+zN9xwQyp/3XXXpfJXX311Kj8Xr3vd61L50047LZU/+eSTU/nDDz88lV+5cmUqP5frkFprehvok1122SWVf8tb3pLKZ6/VIiK+/e1vp/LZeTQ+nvsScHa+ZD9+lusKdsT8u1IGAAAAAADYQQoQAAAAAACgOdssQEopnymlrCul3L3FYx8ppTxeSrlj9r9V3S4TgNaYLwAMmtkCQBfMF4DRtT13gHw2It62lcf/d631qNn/rh3ssgDogc+G+QLAYH02zBYABu+zYb4AjKRtFiC11hsiYmInrAWAHjFfABg0swWALpgvAKNrR34GyOpSyp2ztwHu/XKhUsrppZRbSym37sC+AOgP8wWAQTNbAOiC+QIwz821APnriHhNRBwVEWsj4s9eLlhrvajWuqLWumKO+wKgP8wXAAbNbAGgC+YLwAiYUwFSa32i1jpda52JiL+JiKMHuywA+sh8AWDQzBYAumC+AIyGORUgpZT9t/jjuyLi7sEsB4A+M18AGDSzBYAumC8Ao2F8W4FSyuURcXxE7FtKeSwi/mdEHF9KOSoiakQ8FBG/1eEaAWiQ+QLAoJktAHTBfAEYXdssQGqt793Kw3/XwVoA6BHzBYBBM1sA6IL5AjC6tlmADNOCBQtS+ZNOOimVL6Wk8nMxPt7t/+IHH3wwlX/3u9+dyt99d+4Ozunp6VR+Lk444YRUPvs8r1+/PpVn27LPwerVq1P57OfZxo0bU/mIiKeffjq9DWRkP0+OOOKIVP6jH/1oKr9o0aJUfmZmJpX/6le/msqPjeXftfMnf/InU/nFixen8itXrkzl99prr1T+8MMP7zQ/l/+n2XPhmjVrUvnHH388lb/wwgtT+e9///upPHQpe96stab3kX3Nc8cdd6TyO+O1f99kn+drr702lf+93/u9VD57vbkz3Hfffan8DTfckMofc8wxqfyyZctS+Q9+8IOpfHb9ERFf+cpXUvns+Qi6ln2dmr12+dmf/dlU/rDDDkvl5/L1xg984AOp/KmnnprKP/XUU6n8pZdemsqfdtppqfwee+yRyl988cWpfETERRddlMpPTEyk98FomNPPAAEAAAAAAJjPFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzxoe9gB9neno6lV+zZk0qv2LFilR+LtatW5fKX3LJJan8DTfckMrfeeedqXytNZXfGTZs2DDsJZA0NpbrWvfff/+OVvK8J598Mr3Nc88918FK4EVLly5N5c8444xU/rWvfW0q37XFixen8pdeeml6H3vssUcqv3DhwlR+v/326/TjZ8+d2fzO8PrXvz6Vn5ycTOV32WWXVP7CCy9M5ScmJlJ5+m1mZiaVv+mmm1L522+/PZWPyP8b/ta3vpXKZ4+ZwbvjjjtS+UcffbSjlcxf2evHG2+8MZV/5zvfmcpnZ9fKlStT+YiIr3/966m8ax26tmjRolR+1apVqfyxxx6byr/1rW9N5cfHu//y6ZIlSzrNZ7++d+ihh6by2Wuv7GuU5cuXp/IREaWU9Da0af5dKQMAAAAAAOwgBQgAAAAAANAcBQgAAAAAANAcBQgAAAAAANAcBQgAAAAAANAcBQgAAAAAANAcBQgAAAAAANAcBQgAAAAAANAcBQgAAAAAANAcBQgAAAAAANAcBQgAAAAAANAcBQgAAAAAANCc8WEvYJDOP//8VP7pp5/uaCUvuuyyy1L5Bx98sKOVwOhYuHBhKn///fen8n/1V3+VykdEbNq0Kb0N/TU2lv/+gje+8Y2p/Nvf/vZUftGiRal8KSWVzx7zscce2+nHn4+mpqZS+ZmZmVR+cnIylX/88cdT+YiIxYsXp/JLlixJ5XfbbbdU/rTTTkvl//7v/z6Vn5iYSOXpt+zn7Jo1a1L5d7/73an8XMzlvMBwZV+j1lo7Wsn8NT09ncp//vOfT+VXrlyZyi9dujSVP+GEE1L5iIhLLrkklb/zzjvT+6DfstcKxxxzTCp/8cUXp/K77757Kp+VPd7seSci/3WKH/7wh6l89vrx3nvvTeVvvvnmVP6qq65K5R966KFUPiL/2ox2jf5XEwAAAAAAAF5CAQIAAAAAADRHAQIAAAAAADRHAQIAAAAAADRHAQIAAAAAADRHAQIAAAAAADRHAQIAAAAAADRHAQIAAAAAADRHAQIAAAAAADRHAQIAAAAAADRHAQIAAAAAADRnfNgLGKSHHnoolf/kJz/ZzUK2MDU11fk+YL6bnp5O5X/nd34nlV+4cGEq/8gjj6TykHXwwQent/nVX/3VVH7fffdN7yNjw4YNnebHx3MvQWZmZlL5iIg777wzlX/mmWdS+SeeeCKV/8IXvpDKP/XUU6l89jXH448/nspHROy9996p/Mknn5zK/8mf/EkqPzbme3kYXdnzWvZah25kn7fNmzen8tlz+Zo1azr9+H101113pfKbNm1K5ZcuXZrKH3rooal8RMSb3/zmVP7b3/52Ku/fEbXWVP6b3/xmKv/FL34xlV+5cmUqf8ABB6TyixYtSuUnJydT+YiIc889N5XPvpa/4IILUvnstcjGjRtTeecRdiZXjQAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHPGh72AYZqamhr2EoCtuOeee4a9BNgh73rXu9LbvOlNb0rlx8a6/R6GCy+8MJW/5JJLUvlddtkllZ+Lxx9/PJXfvHlzKv+DH/yg0/x8tG7dulT+W9/6Vir/9NNPp/K33HJLKr9p06ZUHmjbXK4Hzz///FT+8ssvT+8j4+GHH+704/fR5ORkKp+dLdnXG9PT06k8zEfZ18G/8Ru/kcq/6lWvSuX/9m//NpV/y1vekso/9thjqXxE/nyePZc88MADqTy0xB0gAAAAAABAc7ZZgJRSDiyl/Esp5d5Syj2llN+dfXxJKeVrpZT7Z3/du/vlAtAK8wWAQTNbAOiC+QIwurbnDpCpiPgftdb/FhHHRMQHSymHRcTZEfHPtdZDI+KfZ/8MANvLfAFg0MwWALpgvgCMqG0WILXWtbXW22d//0xE3BsRB0TEKRFx8Wzs4oh4Z1eLBKA95gsAg2a2ANAF8wVgdKV+Bkgp5eCI+OmI+GZE7FdrXRvx/CCIiGWDXhwA/WC+ADBoZgsAXTBfAEbL+PYGSym7R8SXIuKMWuvTpZTt3e70iDh9bssDoHXmCwCDZrYA0AXzBWD0bNcdIKWUhfH8Cf6yWus/zD78RCll/9m/3z8i1m1t21rrRbXWFbXWFYNYMADtMF8AGDSzBYAumC8Ao2mbBUh5vs7+u4i4t9b651v81Zcj4v2zv39/RFw1+OUB0CrzBYBBM1sA6IL5AjC6tuctsN4YEb8SEXeVUu6Yfez3I+KciPhCKeXXI+KRiHh3N0sEoFHmCwCDZrYA0AXzBWBEbbMAqbXeFBEv96aGbx7scgDoC/MFgEEzWwDogvkCMLq262eAAAAAAAAAjJLteQssAOi1BQsWpPI/93M/l97Hrrvumt4m47/+679S+c9//vOp/H333ZfK11pTeeaH59/+evvtvvvuqXz239EnPvGJVH7Dhg2pPMBLTUxMdJpn+NauXZvKf/zjH0/l3/CGN6TyS5YsSeUjIq688spUfmpqKr0P6NLMzEwq/4pXvCKVP/B76nUaAAAgAElEQVTAA1P5ncH1EXTHHSAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzFCAAAAAAAEBzxoe9AADY2cbGcv3/qlWrUvkTTzwxlY/Ir2lqaiqVv+CCC1L5u+66K5WvtabyjKbs87xmzZpU/qabbkrlp6enU3kA2JbJyclU/itf+Uoqf/3116fyr3zlK1P5iIinn346vQ30Sfbaa2ZmJpXPXkvNZR/A9nMHCAAAAAAA0BwFCAAAAAAA0BwFCAAAAAAA0BwFCAAAAAAA0BwFCAAAAAAA0BwFCAAAAAAA0BwFCAAAAAAA0BwFCAAAAAAA0BwFCAAAAAAA0BwFCAAAAAAA0BwFCAAAAAAA0JzxYS8AAHa2sbFc/3/UUUel8osWLUrl52JiYiKV/9d//ddUvtaaysMgTE9PD3sJAJAyMzPTaf6pp55K5YHBy37e3nPPPZ3vA9h+7gABAAAAAACaowABAAAAAACaowABAAAAAACaowABAAAAAACaowABAAAAAACaowABAAAAAACaowABAAAAAACaowABAAAAAACaowABAAAAAACaowABAAAAAACaowABAAAAAACaMz7sBQAAEZOTk6n8ddddl8rffPPNqTwAAMAomJqaSuU3bdqUytdaU/mZmZlUHuiWO0AAAAAAAIDmKEAAAAAAAIDmKEAAAAAAAIDmKEAAAAAAAIDmKEAAAAAAAIDmKEAAAAAAAIDmKEAAAAAAAIDmKEAAAAAAAIDmKEAAAAAAAIDmKEAAAAAAAIDmKEAAAAAAAIDmKEAAAAAAAIDmjA97AQCws01NTaXyl1xySUcredGmTZtS+csvvzyVX79+fSoPAAAwCtauXZvKf+ITn0jlP/zhD6fyGzZsSOWBbrkDBAAAAAAAaM42C5BSyoGllH8ppdxbSrmnlPK7s49/pJTyeCnljtn/VnW/XABaYb4AMGhmCwBdMF8ARtf2vAXWVET8j1rr7aWUPSLitlLK12b/7n/XWv9Xd8sDoGHmCwCDZrYA0AXzBWBEbbMAqbWujYi1s79/ppRyb0Qc0PXCAGib+QLAoJktAHTBfAEYXamfAVJKOTgifjoivjn70OpSyp2llM+UUvZ+mW1OL6XcWkq5dYdWCkCzzBcABs1sAaAL5gvAaNnuAqSUsntEfCkizqi1Ph0Rfx0Rr4mIo+L5FvzPtrZdrfWiWuuKWuuKAawXgMaYLwAMmtkCQBfMF4DRs10FSCllYTx/gr+s1voPERG11idqrdO11pmI+JuIOLq7ZQLQIvMFgEEzWwDogvkCMJq2WYCUUkpE/F1E3Ftr/fMtHt9/i9i7IuLuwS8PgFaZLwAMmtkCQBfMF4DRtc0fgh4Rb4yIX4mIu0opd8w+9vsR8d5SylERUSPioYj4rU5WCECrzBcABs1sAaAL5gvAiNpmAVJrvSkiylb+6trBLweAvjBfABg0swWALpgvAKNru38IOgAAAAAAwKgotdadt7NSdt7OANp2W611xbAXMV/Mt/kyPr497zD5o7LzeHp6Or0PgG2ptW7tu1t7ab7NFoAR5tplC+bL6FmwYEEqP5evtc7MzKS3gb7b3msXd4AAAAAAAADNUYAAAAAAAADNUYAAAAAAAADNUYAAAAAAAADNUYAAAAAAAADNUYAAAAAAAADNUYAAAAAAAADNUYAAAAAAAADNUYAAAAAAAADNUYAAAAAAAADNUYAAAAAAAADNGR/2AgCgNVNTU8NeAgAAAAMwPT097CUAO8AdIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHMUIAAAAAAAQHPGd/L+1kfEw1t5fN/Zv+uTvh1z3443wjH3wTCP96Ah7Xe+Ml+e17fjjXDMfdC3440Y3jGbLT/KbHlR3465b8cb4Zj7wLXL/GG+PK9vxxvhmPugb8cbMQLXLqXW2uVCtm8Rpdxaa10x7HXsTH075r4db4Rj7oO+He8o6ttz1LfjjXDMfdC3443o5zGPkj4+P3075r4db4Rj7oO+He8o6ttz1LfjjXDMfdC3440YjWP2FlgAAAAAAEBzFCAAAAAAAEBz5ksBctGwFzAEfTvmvh1vhGPug74d7yjq23PUt+ONcMx90LfjjejnMY+SPj4/fTvmvh1vhGPug74d7yjq23PUt+ONcMx90LfjjRiBY54XPwMEAAAAAABgkObLHSAAAAAAAAADM/QCpJTytlLKfaWUB0opZw97PV0rpTxUSrmrlHJHKeXWYa+nC6WUz5RS1pVS7t7isSWllK+VUu6f/XXvYa5x0F7mmD9SSnl89rm+o5SyaphrHKRSyoGllH8ppdxbSrmnlPK7s483+zz/mGNu9nkeZX2bLRHmS6PnnV7Nloj+zRezZfT0bb6YLW2dc17Qt/nSt9kSYb6Mmr7NlgjzpdHzTq9mS0T/5ssoz5ahvgVWKWVBRPxnRJwQEY9FxL9HxHtrrd8e2qI6Vkp5KCJW1FrXD3stXSmlrIyIZyPic7XWI2Yf+1RETNRaz5kd6HvXWs8a5joH6WWO+SMR8Wyt9X8Nc21dKKXsHxH711pvL6XsERG3RcQ7I+JXo9Hn+ccc86nR6PM8qvo4WyLMl0bPO72aLRH9my9my2jp43wxW9o657ygb/Olb7MlwnwZJX2cLRHmS6PnnV7Nloj+zZdRni3DvgPk6Ih4oNb6YK31hxFxRUScMuQ1sYNqrTdExMRLHj4lIi6e/f3F8fwnSDNe5pibVWtdW2u9ffb3z0TEvRFxQDT8PP+YY2b+MVsa1bf50rfZEtG/+WK2jBzzpUF9my0R/ZsvfZstEebLiDFbGtW3+dK32RLRv/kyyrNl2AXIARHx6BZ/fixG5H/cDqgR8dVSym2llNOHvZidaL9a69qI5z9hImLZkNezs6wupdw5eytgE7e8vVQp5eCI+OmI+Gb05Hl+yTFH9OB5HjF9nC0R5kvT552X6MU5p2/zxWwZCX2cL2ZLo+ecl9H8eadvsyXCfBkBfZwtEeZL0+edl+jFOadv82XUZsuwC5CylceG955cO8cba61viIi3R8QHZ28Ro01/HRGviYijImJtRPzZcJczeKWU3SPiSxFxRq316WGvZ2fYyjE3/zyPoD7OlgjzpS96cc7p23wxW0ZGH+eL2dIfzZ93+jZbIsyXEdHH2RJhvvRFL845fZsvozhbhl2APBYRB27x51dFxPeGtJadotb6vdlf10XElfH87Y598MTse8W98J5x64a8ns7VWp+otU7XWmci4m+isee6lLIwnj/hXVZr/YfZh5t+nrd2zK0/zyOqd7MlwnyJaPO881J9OOf0bb6YLSOld/PFbGnvnPNyWj/v9G22RJgvI6R3syXCfIlo87zzUn045/RtvozqbBl2AfLvEXFoKeXVpZRXRMR/j4gvD3lNnSml7Db7Q2KilLJbRLw1Iu4e7qp2mi9HxPtnf//+iLhqiGvZKV442c16VzT0XJdSSkT8XUTcW2v98y3+qtnn+eWOueXneYT1arZEmC/R6Hlna1o/5/RtvpgtI6dX88Vsae+c8+O0fN7p22yJMF9GTK9mS4T5Eo2ed7am9XNO3+bLKM+WUutw76wrpayKiL+IiAUR8Zla6yeGuqAOlVIOieeb7YiI8Yj4Py0ebynl8og4PiL2jYgnIuJ/RsQ/RsQXImJ5RDwSEe+utTbzw5Fe5piPj+dv/6oR8VBE/NYL7wE46kopx0XEjRFxV0TMzD78+/H8e/81+Tz/mGN+bzT6PI+yPs2WCPMl2j3v9Gq2RPRvvpgto6dP88Vsae+c84K+zZe+zZYI82XU9Gm2RJgv0e55p1ezJaJ/82WUZ8vQCxAAAAAAAIBBG/ZbYAEAAAAAAAycAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgQAAAAAAGiOAgT+H3t3G6N3Xed7/PtrZ04ZqrW1tWTjKe3SLBJaOKjNGkERORa33kCt2LqEuA828kBJeFJuomKrEj0SngoWyCJG9OgTehP1IJAIxZvkuIiymrMu0lOlGGg7tTVtHTsz/31gN8uyuvCdua7OzHderydth88115/Szu+65s01AwAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlDNwKu+stdadyvsDKOxA13WvmeqLmC6cLwC90XVdm+prmC6cLQA947nLCzhfAHrj5T538QoQgJlp71RfAAAAwMvguQsAU0YAAQAAAAAAyplUAGmt/U1r7Z9ba0+11m7q1UUBMLs5XwDoNWcLAP3gfAGY3iYcQFprcyPiCxGxLiLOjYi/ba2d26sLA2B2cr4A0GvOFgD6wfkCMP1N5hUgfx0RT3Vd93TXdX+IiP8dEVf05rIAmMWcLwD0mrMFgH5wvgBMc5MJIK+NiF+/4NfPnHzbf9Bau6a19qPW2o8mcV8AzB7OFwB6zdkCQD84XwCmuYFJ3Lb9ibd1/+kNXXdnRNwZEdFa+0//HABexPkCQK85WwDoB+cLwDQ3mVeAPBMRy17w6/8eEc9O7nIAwPkCQM85WwDoB+cLwDQ3mQDyfyPir1prf9la+28R8cGI2NmbywJgFnO+ANBrzhYA+sH5AjDNTfhLYHVdN9pauzYiHoiIuRHxD13X/axnVwbArOR8AaDXnC0A9IPzBWD6a1136r70oK9zCNAz/9h13ZqpvojpwvkC0Btd1/2pr2U+KzlbAHrGc5cXcL4A9MbLfe4ymW+CDgBAnwwMTL+HaaOjo1N9CQCcQnPmTOarZr884+Pjfb8PAGD26v+jGQAAAAAAgFNMAAEAAAAAAMoRQAAAAAAAgHIEEAAAAAAAoBwBBAAAAAAAKEcAAQAAAAAAyhFAAAAAAACAcgQQAAAAAACgHAEEAAAAAAAoRwABAAAAAADKEUAAAAAAAIByBqb6AgAAZqLBwcHU/uyzz07tL7vsstR+wYIFqf2RI0dS+4iIHTt2pPa/+tWvUvvR0dHUHqCa1lpqv3jx4tR+4cKFqf3q1atT+4l44oknUvt9+/al9idOnEjtAYBavAIEAAAAAAAoRwABAAAAAADKEUAAAAAAAIByBBAAAAAAAKAcAQQAAAAAAChHAAEAAAAAAMoRQAAAAAAAgHIEEAAAAAAAoBwBBAAAAAAAKEcAAQAAAAAAyhFAAAAAAACAcgam+gIAAGaiRYsWpfabN29O7a+88srUft68ean9yMhIah8Rcckll6T2Dz/8cGr/1a9+NbU/cOBAag9wqg0NDaX2GzZsSO23bNmS2i9fvjy177outW+tpfYREcPDw6n93Xffndrfcsstqf1EzkcAYPryChAAAAAAAKAcAQQAAAAAAChHAAEAALvP5VgAACAASURBVAAAAMoRQAAAAAAAgHIEEAAAAAAAoBwBBAAAAAAAKEcAAQAAAAAAyhFAAAAAAACAcgQQAAAAAACgHAEEAAAAAAAoRwABAAAAAADKEUAAAAAAAIByBqb6AgAApoN58+al9mvXrk3t3/a2t6X28+fPT+2zBgbyDwPf/e53p/Zr1qxJ7fft25fab9++PbUfGxtL7QEma/369an91q1bU/uzzjortR8ZGUntt23bltqfeeaZqX1ExIUXXpjaX3vttan9Pffck9o//fTTqT0AML15BQgAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAAADlDEz1BQAA9ENrLbU/55xzUvvNmzen9suXL0/ts0ZHR/v6/iMiBgZyDx2XLl2a2m/atCm1f/TRR1P7/fv3p/YAL5Y9W97xjnek9itWrEjtx8fHU/sHHnggtf/EJz6R2s+fPz+1j4i4+OKLU/trrrkmtV+5cmVqv2fPntS+67rUHgA4tbwCBAAAAAAAKEcAAQAAAAAAypnUl8Bqrf3/iPhdRIxFxGjXdWt6cVEAzG7OFwD6wfkCQK85WwCmt158D5C3d113oAfvBwBeyPkCQD84XwDoNWcLwDTlS2ABAAAAAADlTDaAdBHxndbaP7bWrvlTg9baNa21H7XWfjTJ+wJg9nC+ANAP/+X54mwBYAI8dwGYxib7JbAu6rru2dba0oh4sLX2/7que/SFg67r7oyIOyMiWmvdJO8PgNnB+QJAP/yX54uzBYAJ8NwFYBqb1CtAuq579uSPz0fE/RHx1724KABmN+cLAP3gfAGg15wtANPbhANIa21+a+2V//bziLgsIv6pVxcGwOzkfAGgH5wvAPSaswVg+pvMl8A6IyLub6392/v5atd1/6cnVwXAbOZ8AaAfnC8A9JqzBWCam3AA6bru6Yj4Hz28FgBwvgDQF84XAHrN2QIw/U32m6ADAExLy5cvT+03b96c2p9zzjmpfdaePXtS++3bt/fpSv7d+vXrU/sVK1ak9ueff35qv2jRotR+//79qT3Ai3Vd7nsXHz58uK/v/9ChQ6n9fffdl9ofPXq0r/uIiJ07d6b2r3vd61L748ePp/YAkzV37tz0bZYtW5baHzlyJLUfHh5O7eFPmTMn9900xsfH+3QlOZP6JugAAAAAAADTkQACAAAAAACUI4AAAAAAAADlCCAAAAAAAEA5AggAAAAAAFCOAAIAAAAAAJQjgAAAAAAAAOUIIAAAAAAAQDkCCAAAAAAAUI4AAgAAAAAAlCOAAAAAAAAA5QxM9QUwvQ0M5P6ILFq0KH0fr3rVq9K3yfjtb3+b2h84cKBPVzIxc+bkO+W8efNS+zPOOCO1z/65OHz4cGo/PDyc2o+NjaX2wMyT/bgTEfH+978/tV+/fn1qn/1Yu2fPntT+k5/8ZGq/ffv21H4innzyydT+1ltvTe2zjyPOP//81P6Xv/xlau98AV5s6dKlqf1VV12V2mcf++/evTu1f+SRR1L7U+EPf/hDan/HHXek9l3X9XUP1Dc0NJTa33777en72LBhQ2p/2223pfaf+cxnUntmnuzz0w9+8IPp+3jTm96U2t98882p/cGDB1P7l8srQAAAAAAAgHIEEAAAAAAAoBwBBAAAAAAAKEcAAQAAAAAAyhFAAAAAAACAcgQQAAAAAACgHAEEAAAAAAAoRwABAAAAAADKEUAAAAAAAIByBBAAAAAAAKAcAQQAAAAAAChnYKovYCq9+tWvTt9mwYIFqf1zzz2X2o+Ojqb2CxcuTO2XLVuW2r/97W9P7d/85jen9hERq1atSt8m44c//GFqf+ONN6b2hw4dSu0XLVqU2l900UWpfUTEhRdemNpfcsklqf0rXvGK1P7JJ59M7b/+9a+n9rt3707t9+/fn9pHRHRdl74N0DsTObOzZ9LQ0FBqf/To0dT+y1/+cmp///33p/bHjh1L7Sfi+9//fmo/PDyc2q9cuTK137hxY2r/yCOPpPYTOS+AmWPOnPz/D5h9bL548eLUfmRkJLX/wQ9+kNpnn7tMR9mzBeDFso/7N2zYkNpv2rQptY+IGBwcTO0HBmb1p3RnhaVLl6b269atS+1vvfXW1D4i/3yqtZa+j37wChAAAAAAAKAcAQQAAAAAAChHAAEAAAAAAMoRQAAAAAAAgHIEEAAAAAAAoBwBBAAAAAAAKEcAAQAAAAAAyhFAAAAAAACAcgQQAAAAAACgHAEEAAAAAAAoRwABAAAAAADKGZjqC+iluXPnpvZXXXVV+j6uvvrq1P6xxx5L7Y8ePZrar1q1KrW/4IILUvszzjgjtR8cHEztIyLmzOlvh1u+fHlqv2DBgtT+Zz/7WWp/7rnnpvYXXXRRah8Rcfrpp6f2Bw4cSN9Hxrp161L7t771ran9rl27UvuPfexjqX1E/3+PYLY57bTTUvvsx5GIiLe85S2p/cjISGq/ffv21P7ee+9N7Y8dO5banwqHDh1K7X/+85+n9itXrkztzzzzzNR+/vz5qf3+/ftTe2BmmcjzkNWrV6f22eeozz33XGr/3e9+N7UfHR1N7QFmgiVLlqT2d911V2r/zne+M7UfGhpK7SMiuq5L7bPPjz796U+n9mNjY6n9bJT93Nv111+f2m/cuDG1f81rXpPaL168OLWPiPja176W2g8PD6fvox+8AgQAAAAAAChHAAEAAAAAAMoRQAAAAAAAgHIEEAAAAAAAoBwBBAAAAAAAKEcAAQAAAAAAyhFAAAAAAACAcgQQAAAAAACgHAEEAAAAAAAoRwABAAAAAADKEUAAAAAAAIByBqb6AnqptZbaL168OH0fr3/961P7N7zhDen7yJgzJ9ewuq5L7ffu3Zva79ixI7WPiDhy5Ehqv2DBgtT+fe97X2p/xRVXpPbvfe97U/vsn9Psf4OIiG3btqX2u3btSu2z/w7XXXddan/llVem9pdeemlqv2LFitQ+IuLgwYOpffbvGsx02fNo7dq1qf3HP/7x1D4if85/61vfSu0/9alPpfYT+Xg+042Pj6f2+/fvT+3vuOOO1P43v/lNag/wYtnzLuvEiROp/eHDh/t0JQBTZ8mSJan93XffndpffvnlqX32Me3nP//51D4i4gMf+EBqv3v37tR+bGwsta9gaGgotb/ssstS+61bt6b2e/bsSe03bNiQ2l999dWp/Yc//OHUPiLiscceS+2zf3f6xStAAAAAAACAcgQQAAAAAACgnJcMIK21f2itPd9a+6cXvO3VrbUHW2v/cvLHRf29TACqcb4A0A/OFwB6zdkCMHO9nFeAfCki/uZFb7spIh7uuu6vIuLhk78GgIwvhfMFgN77UjhfAOitL4WzBWBGeskA0nXdoxEx/KI3XxER9578+b0Rsb7H1wVAcc4XAPrB+QJArzlbAGauiX4PkDO6rvtNRMTJH5f27pIAmMWcLwD0g/MFgF5ztgDMAAP9voPW2jURcU2/7weA2cX5AkCvOVsA6AfnC8DUmegrQJ5rrf1FRMTJH5//c8Ou6+7sum5N13VrJnhfAMwezhcA+uFlnS/OFgASPHcBmAEmGkB2RsTfnfz530XEjt5cDgCznPMFgH5wvgDQa84WgBngJQNIa+1rEfGDiHhda+2Z1trfR8T/ioi1rbV/iYi1J38NAC+b8wWAfnC+ANBrzhaAmeslvwdI13V/+2f+0f/s8bUAMIs4XwDoB+cLAL3mbAGYuSb6JbAAAAAAAACmrZd8BQj/UWsttR8cHEztu65L7UdGRlL7Bx54ILW/5557UvuHHnootY/I/zucfvrpqf2cObnOd9111/X1/e/Zsye137JlS2ofEXH//fen9seOHUvts38PbrvtttT+vPPOS+3PPvvs1P6jH/1oah8RceONN6b2zz//Z7//HZSU/Vh4wQUXpPbLly9P7SMixsfHU/vHH388td+7d29qnz3jp6Ps72n2Y+HOnTtT+29/+9upffYxBwAAk5f9HMJ73vOe1P5d73pXap+V/TzOF7/4xfR9bNiwIbU/cuRI+j5msqGhofRtNm3alNrfdNNNqX32c2k33HBDav/ss8+m9tnPl37ve99L7SMihoeH07eZDrwCBAAAAAAAKEcAAQAAAAAAyhFAAAAAAACAcgQQAAAAAACgHAEEAAAAAAAoRwABAAAAAADKEUAAAAAAAIByBBAAAAAAAKAcAQQAAAAAAChHAAEAAAAAAMoRQAAAAAAAgHIGpvoCmJx9+/al9rfccktq/+Mf/zi1HxsbS+0nYsmSJan9WWed1acr+aPR0dHUfvv27X3dR0QcO3YsfZuMrutS+1/84hep/UMPPZTan3vuuan9unXrUvuIiJ07d6b2O3bsSO3Hx8dTe5huWmup/cBA7iFI9v1HRBw6dCi1/+lPf5ran4ozb7oZHh5O7W+++eY+XckfZa8HqG3OnNz/3zc4ONj3++i37Hna7+ufyPvPPg72uBmm3ty5c1P78847L7X/whe+kNpnPxbed999qf3WrVtT+3nz5qX2ERGvfe1rU/vs52X6benSpal99vMyN9xwQ2ofEfG73/0utf/c5z6X2n/jG99I7Y8fP57ar1mzJrW//PLLU/vbb789tY+Yuc+Bp9ejNwAAAAAAgB4QQAAAAAAAgHIEEAAAAAAAoBwBBAAAAAAAKEcAAQAAAAAAyhFAAAAAAACAcgQQAAAAAACgHAEEAAAAAAAoRwABAAAAAADKEUAAAAAAAIByBBAAAAAAAKCcgam+gF4aHBxM7V/5ylf26Ur+Xdd1qf34+Hhq/8QTT6T2e/fuTe3HxsZS+4kYGMj9MbziiitS+0svvTS1zzpx4kRq/8wzz6T2IyMjqf10NDo6mtofPXq0T1fyR4sWLUrfZvXq1an9rl27Uvvs332YbhYuXJjar1q1KrVvraX2ERG//vWvU/uf/OQnqf1s/HubfVxz8ODBPl0JMBucdtppqf3atWtT+ze+8Y2pfUTExRdfnL5NxuLFi1P7D33oQ6n9448/ntpnLVu2LH2bp556KrV/8MEHU/vf//73qT3MNhN5nH3TTTel9tdee21qn/080b333pvaf+QjH0ntjx8/ntpv2bIltY+I+M53vpPaf+UrX0nth4aGUvuNGzem9p/97GdT++znfa6//vrUPiLim9/8Zmqf/dxVVva/wV133ZXaZ39Pt23bltrPZF4BAgAAAAAAlCOAAAAAAAAA5QggAAAAAABAOQIIAAAAAABQjgACAAAAAACUI4AAAAAAwL+2d/8xepblnsCvu53uCHjS8tumBdpF/tCqICFGw7oBZM1ZTfQQPbrGnLhxEzBBhATDEmOAhKw52YBoCGnQoLhJZXMUXRAwARsVUEIOJeVnxR6gPWuplLYMlVTGzsy9f3SIPWxLew3v23ee+/l8EkL79vvy3DdP5/7O9Oo7LwDNMQABAAAAAACaYwACAAAAAAA0xwAEAAAAAABojgEIAAAAAADQHAMQAAAAAACgOWOjXsAgLV26NJU/55xz0tcYGxvu/7LJyclU/qGHHkrlX3755VT+cFi0aFEqv2zZslR+fHw8la+1pvK///3vU/m1a9em8lNTU6n8fLRkyZJUftWqVan8ggW5We7MzEwqP5drQN8sXrw4lc9+nGfP5oiIX/3qV6n81q1b09cA4NAtXLgwlV+9enUq/5nPfCaVP+KII1L5uSilpPLHHHNMKn/llVem8nP5PDgju9+IiJ07d6by2T3fcsstqTz0zfve9770c774xS+m8ieeeGIq//jjj6fy2XPhz3/+cyqf/bPAj3/846l8RMQNN9yQyr/22mup/BVXXJHKX3TRRan8ww8/nMrfeuutqfxdd92VykdETE9Pp58zTGeeeWYqf+qpp6byN998cyq/e/fuVL7L/IkeAAAAAADQHAMQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHPGRr2AN7NgQW4+c/rpp6fyJ510Uip/OGzcuDGVv++++1L5qampVP5wOO2001L5888/P5UfG8v9Nt++fXsq/61vfSuVf+aZZ1L5FixevDiVX7VqVSqfPSsmJydT+YiIXbt2pZ8D80n246SUkspnP87Hx8dT+bnI7iHbF9n8sGX3u2TJkvQ1svc5a2JiIpXfsWNHKl9rTeWBwTr22GNT+XPPPTeVf/HFF1P5o446KpWPyO8h27979uxJ5bds2TLU/37WXD5n/tnPfpbKr127Nn0N6JMTTjghlb/99tvT11i5cmUq/9xzz6Xyn/rUp1L57PmftXz58lT+Xe96V/oa3/jGN1L57NdTu3fvTuUvueSSVP6uu+5K5efy5zLzzTvf+c5U/sc//nEqf8cdd6TyN910UyrfJ14BAgAAAAAANMcABAAAAAAAaM5BByCllO+VUraVUp7c57FrSilbSinrZ//52HCXCUBr9AsAg6ZbABgG/QLQXYfyCpBbI+Jv9/P4DbXWM2b/uWewywKgB24N/QLAYN0augWAwbs19AtAJx10AFJrvT8idh6GtQDQI/oFgEHTLQAMg34B6K638h4gXy6lPD77MsCjDxQqpVxYSnmklPLIW7gWAP2hXwAYNN0CwDDoF4B5bq4DkNURcWpEnBERWyPi+gMFa63fqbWeVWs9a47XAqA/9AsAg6ZbABgG/QLQAXMagNRaX6y1TtdaZyLiuxHxgcEuC4A+0i8ADJpuAWAY9AtAN8xpAFJKWbrPTy+IiCcHsxwA+ky/ADBougWAYdAvAN0wdrBAKeW2iDgnIo4rpfwhIq6OiHNKKWdERI2ITRFx0RDXCECD9AsAg6ZbABgG/QLQXQcdgNRaP7efh28ZwloA6BH9AsCg6RYAhkG/AHTXQQcgo7RgQe47dL3nPe9J5ZcsWZLKz8XU1FQq/4tf/CKV37hxYyo/bAsXLkw/57zzzkvlTz311PQ1Mnbu3JnKP/TQQ6n85ORkKj8flVJS+ezH2vj4eCpfa03l5/Jxs3bt2lQ++7EPWdmPk/PPPz+VP+KII1L5M888M5V/xzvekcqPjeU/ZbngggvSz8nYtWvXUP/7WdnPm1atWpW+xlyek/HAAw+k8l//+tdT+W3btqXywJvLnjsf+tCHUvnsmXDjjTem8qecckoqHxHxpS99KZU/99xzU/ktW7ak8hddlPsL588//3wqnzWXz4H/+Mc/pvKvvfZa+hrQZdnPy7/61a+m8itXrkzlIyLWrFmTyl9zzTWp/LPPPpvKD9vWrVtT+auuumpIK/mr+++/P5XfvHlzKr99+/ZUvgXZj7Uf/ehHqfyrr76ayl9++eWpvK91DmxO7wECAAAAAAAwnxmAAAAAAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYYgAAAAAAAAM0xAAEAAAAAAJozNuoFDNKCBbl5TillSCv5q1prKv/KK6+k8nv27Enlhy2734iIzZs3p/KvvvpqKj8+Pp7KP/7446n8yy+/nMq34Nhjj03lL7744lR+6dKlqfz09HQqf99996XyEREbN25MPweGadmyZan8VVddlcqvWLEilV+4cGEq/7a3vS2Vn4vsHi655JLhLGSeyn7eNNfnZCxZsiSVv+eee1L5O++8M5WfmZlJ5aFvsh8jzz77bCp/7733pvLr1q1L5Z9//vlUPiLis5/9bPo5GTt27Ejls5+jbtq0KZUHRu/EE09M5c8777xUfi5n4TXXXJPKP/fcc+lrzCeTk5Op/I033jiklfzV1NTU0K/RdYsWLUrlzzzzzFT+5JNPTuW/8pWvpPIvvfRSKs+BeQUIAAAAAADQHAMQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOaMjXoBg7Rr165UfnJyMn2NWmsq//TTT6fy69evT+VnZmZS+WGby3p+85vfpPJr1qxJ5bNr+vnPf57K79ixI5VvwZIlS1L5D37wg6n8+Ph4Kv/SSy+l8r/97W9T+Yi5nReQsWBB7u8knH766an8ihUrUvnjjz8+lR+2UsrQr7Fo0aKhX2OYsp+jzEfZjwOgW5555plU/oUXXkjlp6enU/nFixen8hERq1atSuWza3rggQdS+W3btqXyQPdk/6zr+9//fip/9913p/IREZs2bUo/p0+mpqZGvYTmzOXrwc9//vOp/LXXXpvKX3755an8D3/4w1S+ha/v5gtfZQIAAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAcAxAAAAAAAKA5BiAAAAAAAEBzDEAAAAAAAIDmGIAAAAAAAADNMQABAAAAAACaYwACAAAAAAA0Z2zUC3gzU1NTqfxPf/rTVP69731vKh8RcfLJJ6fyV199dSr/yCOPpPIzMzOp/Hz00ksvpfLXXnttKj85OZnK/+Uvf0nlW7gHw5b9f7Rnz55UfvPmzan8Y489lspHuM8M34IFub+TsGrVqlR+8eLFqfx8U2sd9RL+P9PT06l8KWVIK9lr2GdtRMSOHTtS+eyeN2zYkMqvX78+lXeWw2hlz52dO3cOaSVzl+3r7Dm4fPnyVP7II49M5Xfv3p3KA6OXPQtvuummIa0ERmcuf4Z7/fXXp/L33HNPKn/bbbel8vPxa9q+8AoQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOaMjXoBg7R58+ZU/oorrkhf46ijjkrlX3jhhVR+z549qXwLaq2p/CuvvDKklXCodu7cmcqvXr06lT/66KNT+fXr16fyW7ZsSeXhcJiZmUnlH3vssaHmjz/++FR+6dKlqfz4+HgqPxfZTv3d736Xyq9duzaVX758eSqftWHDhlR+YmIifY1169al8tn7vHHjxlTeeQ4AAO37yEc+kn7OU089lcpfd911qfzk5GQqz+h4BQgAAAAAANAcAxAAAAAAAKA5Bx2AlFJOKqX8spSyoZTyVCnl0tnHjyml3FdK2Tj779z3rAGg1/QLAIOmWwAYBv0C0F2H8gqQqYi4vNb6roj4YERcXEp5d0RcGRFra62nRcTa2Z8DwKHSLwAMmm4BYBj0C0BHHXQAUmvdWmt9dPbHf4qIDRGxLCI+GRE/mI39ICL+bliLBKA9+gWAQdMtAAyDfgHorrFMuJSyIiLeHxEPR8SJtdatEXuLoJRywgGec2FEXPjWlglAy/QLAIOmWwAYBv0C0C2HPAAppbw9Im6PiMtqrbtKKYf0vFrrdyLiO7P/jTqXRQLQLv0CwKDpFgCGQb8AdM+hvAdIlFIWxd4Dfk2t9SezD79YSlk6++tLI2LbcJYIQKv0CwCDplsAGAb9AtBNBx2AlL3j7FsiYkOt9Zv7/NKdEfGF2R9/ISLuGPzyAGiVfgFg0HQLAMOgXwC661C+BdbZEfEPEfFEKWX97GNfi4h/jIh/KqX8t4j414j4++EsEYBG6RcABk23ADAM+gWgow46AKm1PhgRB/qmhh8Z7HIA6Av9AsCg6RYAhkG/AHTXIb8JehfUmnsfqe3bt6evMZfnQGt27tyZyq9evTqVP9Q3knvdzMzMUPNwOGR/X957772p/BNPPJHKH3fccan8pZdemsp/+tOfTuXHx8dT+YiILVu2pPKXXXZZKv/www+n8kceeWQqn/XKK6+k8tnPmyIipqen08/JmMuaAOYqe25G5Pt05cqVqfxTTz2Vyk9MTKTyANBFv/71r9PPufnmm1P53bt3p69BNxzSm6ADAAAAAAB0iQEIAAAAAADQHAMQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDljo14A0L7p6elRLwGaMzk5mcpv2rQpld+8eXMq/+1vfzuVP/vss1P5FStWpPJzsWvXrlR+9+7dQ80DMFwTExPp5zz99NOp/Cc+8Yn0NQCAf+vRRx8d9RLoMK8AAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYYgAAAAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGjO2KgXAADMP7XWVH5iYiKV37NnTyo/F8cff3wq/+EPfziVX79+fSo/PT2dygMwXEuWLEk/593vfncqn+3TmZmZVB4AgDfnFSAAAAAAAEBzDEAAAAAAAIDmGIAAAAAAAADNMQABAAAAAACaYwACAAAAAAA0xwAEAAAAAABojgEIAAAAAADQHAMQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAAAAAAzRkb9QIAgO6bmppK5ScmJlL5PXv2pPIREbt27UrlN2/enMrXWlN5AOaXuZzj2W65++67U/k1a9ak8tn+BQDoG68AAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYYgAAAAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANCcUms9fBcr5fBdDp0+WQAACWRJREFUDKBt62qtZ416EfOFfhm98fHxVP6jH/1oKn/GGWek8hERExMTqfxtt92Wym/fvj2Vhy6otZZRr2G+0C3tKyX/2/2UU04Zav7BBx9M5aenp1N5GBFfu+xDvwAMxqF+7eIVIAAAAAAAQHMOOgAppZxUSvllKWVDKeWpUsqls49fU0rZUkpZP/vPx4a/XABaoV8AGDTdAsAw6BeA7ho7hMxURFxea320lPI3EbGulHLf7K/dUGu9bnjLA6Bh+gWAQdMtAAyDfgHoqIMOQGqtWyNi6+yP/1RK2RARy4a9MADapl8AGDTdAsAw6BeA7kq9B0gpZUVEvD8iHp596MullMdLKd8rpRx9gOdcWEp5pJTyyFtaKQDN0i8ADJpuAWAY9AtAtxzyAKSU8vaIuD0iLqu17oqI1RFxakScEXun4Nfv73m11u/UWs+qtZ41gPUC0Bj9AsCg6RYAhkG/AHTPIQ1ASimLYu8Bv6bW+pOIiFrri7XW6VrrTER8NyI+MLxlAtAi/QLAoOkWAIZBvwB000EHIKWUEhG3RMSGWus393l86T6xCyLiycEvD4BW6RcABk23ADAM+gWguw76JugRcXZE/ENEPFFKWT/72Nci4nOllDMiokbEpoi4aCgrBKBV+gWAQdMtAAyDfgHoqIMOQGqtD0ZE2c8v3TP45QDQF/oFgEHTLQAMg34B6K5DfhN0AAAAAACArii11sN3sVIO38UA2rau1nrWqBcxX+iX7lmwIPd3MLL5iIjs5zjT09Ppa0Braq37+9utvaRbGIRsf83MzAxpJTBSvnbZh34BGIxD/drFK0AAAAAAAIDmGIAAAAAAAADNMQABAAAAAACaYwACAAAAAAA0xwAEAAAAAABojgEIAAAAAADQHAMQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmjM26gUAAP0zMzMz1DwAzAf6CwBgtLwCBAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYYgAAAAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAcAxAAAAAAAKA5Y4f5etsjYvN+Hj9u9tf6pG977tt+I+y5D0a531NGdN35Sr/s1bf9RthzH/RtvxGj27Nu+bd0y1/1bc9922+EPfeBr13mD/2yV9/2G2HPfdC3/UZ04GuXUmsd5kIObRGlPFJrPWvU6zic+rbnvu03wp77oG/77aK+3aO+7TfCnvugb/uN6Oeeu6SP96dve+7bfiPsuQ/6tt8u6ts96tt+I+y5D/q234hu7Nm3wAIAAAAAAJpjAAIAAAAAADRnvgxAvjPqBYxA3/bct/1G2HMf9G2/XdS3e9S3/UbYcx/0bb8R/dxzl/Tx/vRtz33bb4Q990Hf9ttFfbtHfdtvhD33Qd/2G9GBPc+L9wABAAAAAAAYpPnyChAAAAAAAICBMQABAAAAAACaM/IBSCnlb0spz5RS/qWUcuWo1zNspZRNpZQnSinrSymPjHo9w1BK+V4pZVsp5cl9HjumlHJfKWXj7L+PHuUaB+0Ae76mlLJl9l6vL6V8bJRrHKRSykmllF+WUjaUUp4qpVw6+3iz9/lN9tzsfe6yvnVLhH5p9NzpVbdE9K9fdEv39K1fdEtbZ87r+tYvfeuWCP3SNX3rlgj90ui506tuiehfv3S5W0b6HiCllIUR8fuI+E8R8YeI+OeI+Fyt9emRLWrISimbIuKsWuv2Ua9lWEop/zEiXo2I/1Vrfc/sY/8zInbWWv9xttCPrrX+91Guc5AOsOdrIuLVWut1o1zbMJRSlkbE0lrro6WUv4mIdRHxdxHxX6PR+/wme/5MNHqfu6qP3RKhXxo9d3rVLRH96xfd0i197Bfd0taZ87q+9UvfuiVCv3RJH7slQr80eu70qlsi+tcvXe6WUb8C5AMR8S+11udqrX+JiP8dEZ8c8Zp4i2qt90fEzjc8/MmI+MHsj38Qez9AmnGAPTer1rq11vro7I//FBEbImJZNHyf32TPzD+6pVF965e+dUtE//pFt3SOfmlQ37olon/90rduidAvHaNbGtW3fulbt0T0r1+63C2jHoAsi4j/u8/P/xAd+R/3FtSIuLeUsq6UcuGoF3MYnVhr3Rqx9wMmIk4Y8XoOly+XUh6ffSlgEy95e6NSyoqIeH9EPBw9uc9v2HNED+5zx/SxWyL0S9Pnzhv04szpW7/olk7oY7/olkbPnANo/tzpW7dE6JcO6GO3ROiXps+dN+jFmdO3fulat4x6AFL289jovifX4XF2rfXMiPjPEXHx7EvEaNPqiDg1Is6IiK0Rcf1olzN4pZS3R8TtEXFZrXXXqNdzOOxnz83f5w7qY7dE6Je+6MWZ07d+0S2d0cd+0S390fy507duidAvHdHHbonQL33RizOnb/3SxW4Z9QDkDxFx0j4/Xx4RL4xoLYdFrfWF2X9vi4ifxt6XO/bBi7PfK+717xm3bcTrGbpa64u11ula60xEfDcau9ellEWx98BbU2v9yezDTd/n/e259fvcUb3rlgj9EtHmufNGfThz+tYvuqVTetcvuqW9M+dAWj93+tYtEfqlQ3rXLRH6JaLNc+eN+nDm9K1futotox6A/HNEnFZKWVlK+XcR8V8i4s4Rr2loSilHzb5JTJRSjoqIj0bEk6Nd1WFzZ0R8YfbHX4iIO0a4lsPi9cNu1gXR0L0upZSIuCUiNtRav7nPLzV7nw+055bvc4f1qlsi9Es0eu7sT+tnTt/6Rbd0Tq/6Rbe0d+a8mZbPnb51S4R+6ZhedUuEfolGz539af3M6Vu/dLlbSq2jfWVdKeVjEfGtiFgYEd+rtf6PkS5oiEop/z72TrYjIsYi4oct7reUcltEnBMRx0XEixFxdUT8n4j4p4g4OSL+NSL+vtbazJsjHWDP58Tel3/ViNgUERe9/j0Au66U8h8i4oGIeCIiZmYf/lrs/d5/Td7nN9nz56LR+9xlfeqWCP0S7Z47veqWiP71i27pnj71i25p78x5Xd/6pW/dEqFfuqZP3RKhX6Ldc6dX3RLRv37pcreMfAACAAAAAAAwaKP+FlgAAAAAAAADZwACAAAAAAA0xwAEAAAAAABojgEIAAAAAADQHAMQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5vw/7iOgddpNRCwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2016x2016 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(28, 28))\n",
    "columns = 4\n",
    "rows = 2\n",
    "image_index = 0\n",
    "for i in range(1, columns * rows + 1):\n",
    "    figure.add_subplot(rows, columns, i)\n",
    "    while train_y[image_index] == 0:\n",
    "        image_index += 1\n",
    "    print(image_index)\n",
    "    plt.imshow(train_x[image_index], cmap='gray')\n",
    "    image_index +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Tensorflow model\n",
    "The model is created similiar to the example given at https://www.tensorflow.org/guide/eager\n",
    "\n",
    "The network is made up of several convolutional layers with maxpool layers inbetween"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOFCnn(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MOFCnn, self).__init__()\n",
    "        # CNN layers\n",
    "        self.cnn1 = tf.layers.Conv2D(32, 3, input_shape=(1, 28, 28), activation='relu', data_format=\"channels_first\")\n",
    "        self.cnn2 = tf.layers.Conv2D(64, 3, activation='relu', data_format=\"channels_first\")\n",
    "        self.cnn3 = tf.layers.Conv2D(128, 3, activation='relu', data_format=\"channels_first\")\n",
    "        \n",
    "        # maxpool layers:\n",
    "        self.maxpool = tf.layers.MaxPooling2D((2, 2), (2,2))\n",
    "        \n",
    "        # flatten layer:\n",
    "        self.flatten = tf.layers.Flatten()\n",
    "        \n",
    "        # fully connected layers\n",
    "        self.dense1 = tf.layers.Dense(10000, activation='relu')\n",
    "        self.denseOutput = tf.layers.Dense(3, activation='softmax')\n",
    "    \n",
    "    def call(self, input):\n",
    "        result = self.cnn1(input)\n",
    "        result = self.maxpool(result)\n",
    "        result = self.cnn2(result)\n",
    "        result = self.maxpool(result)\n",
    "        result = self.cnn3(result)\n",
    "        result = self.maxpool(result)\n",
    "        result = self.flatten(result)\n",
    "        result = self.dense1(result)\n",
    "        result = self.denseOutput(result)\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss(model, x, y):\n",
    "        prediction = model(x)\n",
    "        return tf.losses.softmax_cross_entropy(onehot_labels=y, logits=prediction)\n",
    "    \n",
    "    @staticmethod\n",
    "    def grad(model, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = MOFCnn.loss(model, inputs, targets)\n",
    "        return tape.gradient(loss_value, model.variables)\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(predictions, labels):\n",
    "        model_pred = tf.argmax(predictions, axis=1,output_type=tf.int64)\n",
    "        actual_labels = tf.argmax(labels, axis=1, output_type=tf.int64)\n",
    "        return tf.reduce_sum(tf.cast(tf.equal(model_pred, actual_labels),dtype=tf.float32)) / float(predictions.shape[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainMofCnn(model, x, y, batch_size, number_of_epochs):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    x = tf.data.Dataset.from_tensor_slices(x)\n",
    "    y = tf.data.Dataset.from_tensor_slices(y)\n",
    "    data = tf.data.Dataset.zip((x, y)).batch(batch_size)\n",
    "    for _ in range(number_of_epochs):\n",
    "        for xs, ys in data:\n",
    "            clear_output(True)\n",
    "            grads = MOFCnn.grad(model, xs, ys)\n",
    "            optimizer.apply_gradients(zip(grads, model.variables))\n",
    "            loss = MOFCnn.loss(model, xs, ys)\n",
    "            predictions = model(xs)\n",
    "            print(\"loss: {:.3f}\".format(loss))\n",
    "            print(ys)\n",
    "            print(tf.contrib.metrics.accuracy(predictions, ys))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting the training data\n",
    "First the train X data needs to be converted from a numpy array of 64 bit integers in the 0-255 range, to a format that tensorflow understands; a tensor of 32 bit floats in the 0.0-1.0 range.\n",
    "\n",
    "Fortunately tensorflow has a convenient helper function for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = tf.image.convert_image_dtype([train_x], dtype=tf.float32)\n",
    "train_x = tf.reshape(train_x, (-1, 1, 28, 28))\n",
    "#x_float = tf.data.Dataset.from_tensor_slices(x_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = tf.one_hot(train_y, 3, dtype=tf.int32)\n",
    "train_y = tf.reshape(train_y, (-1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MOFCnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.086\n",
      "tf.Tensor(\n",
      "[[1 0 0]\n",
      " [1 0 0]], shape=(2, 3), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dtypes of predictions and labels should match. Given: predictions (tf.float32) and labels (tf.int32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1fa765bf699d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainMofCnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-dda1b20ce130>\u001b[0m in \u001b[0;36mtrainMofCnn\u001b[1;34m(model, x, y, batch_size, number_of_epochs)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss: {:.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\ml\\mofdetector\\venv\\lib\\site-packages\\tensorflow\\contrib\\metrics\\python\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(predictions, labels, weights, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m     raise ValueError('Dtypes of predictions and labels should match. '\n\u001b[0;32m     57\u001b[0m                      \u001b[1;34m'Given: predictions (%r) and labels (%r)'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                      (predictions.dtype, labels.dtype))\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     is_correct = math_ops.cast(\n",
      "\u001b[1;31mValueError\u001b[0m: Dtypes of predictions and labels should match. Given: predictions (tf.float32) and labels (tf.int32)"
     ]
    }
   ],
   "source": [
    "trainMofCnn(model, train_x, train_y, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=202237, shape=(3,), dtype=int64, numpy=array([0, 0, 0], dtype=int64)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(model(train_x[0:50]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=73315, shape=(3,), dtype=float32, numpy=array([0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 1, 32) dtype=float32, numpy=\n",
       " array([[[[-0.12694576,  0.06382034,  0.13291192,  0.03130699,\n",
       "            0.12868202, -0.01022779, -0.09062007,  0.14021184,\n",
       "           -0.00259737,  0.07491334,  0.03258504,  0.00755625,\n",
       "            0.07130665,  0.14182118,  0.08813372, -0.03113515,\n",
       "           -0.0642942 ,  0.06004222, -0.08445195,  0.13330282,\n",
       "            0.06034362,  0.09137145, -0.09948372,  0.06893794,\n",
       "           -0.13363826, -0.06349997,  0.01761688, -0.10433002,\n",
       "            0.039092  , -0.09855227,  0.03559849,  0.13322444]],\n",
       " \n",
       "         [[-0.10258798,  0.0710118 ,  0.00601129, -0.07210329,\n",
       "            0.0006314 , -0.09130789, -0.12212229,  0.10533248,\n",
       "            0.10855576, -0.12090814, -0.11712475, -0.05703476,\n",
       "            0.01385051, -0.02041751, -0.11272412, -0.03919879,\n",
       "           -0.08920735, -0.04265847, -0.14184272,  0.13222198,\n",
       "            0.06710298, -0.11460084,  0.13170195,  0.04836139,\n",
       "           -0.09360765, -0.13627203,  0.11981951, -0.09635151,\n",
       "            0.0498556 , -0.07002607,  0.14277971,  0.08964777]],\n",
       " \n",
       "         [[ 0.07929523, -0.0635758 , -0.07106159, -0.06733685,\n",
       "            0.07738761, -0.07558749,  0.07337119, -0.11998016,\n",
       "           -0.01686537,  0.00704855, -0.07421897, -0.07319824,\n",
       "           -0.09134699, -0.1310948 ,  0.10801213,  0.10351656,\n",
       "            0.0019821 , -0.0115489 ,  0.13763042, -0.00794233,\n",
       "            0.14061573, -0.1248613 , -0.00686478,  0.0862341 ,\n",
       "            0.00762139,  0.01608271, -0.00672646, -0.01521473,\n",
       "            0.09086291,  0.02029957, -0.13518783, -0.10775382]]],\n",
       " \n",
       " \n",
       "        [[[-0.0171162 ,  0.09378158,  0.04069122,  0.08879849,\n",
       "           -0.11648285, -0.12374167,  0.07689472,  0.03173888,\n",
       "            0.05734923,  0.00251547,  0.07990764, -0.13016531,\n",
       "            0.06762128, -0.01223176, -0.05846907,  0.0275687 ,\n",
       "           -0.01760978, -0.01536873, -0.06705748,  0.02715735,\n",
       "           -0.01760016,  0.00327604, -0.13130082, -0.08683477,\n",
       "           -0.04049767, -0.05249609, -0.0662814 , -0.09125621,\n",
       "           -0.06525942,  0.12040612,  0.08222825, -0.05808073]],\n",
       " \n",
       "         [[ 0.02604883, -0.05576755, -0.07942449,  0.03586356,\n",
       "           -0.06420662,  0.09983488, -0.01453617,  0.03485895,\n",
       "           -0.05215503, -0.11703363,  0.11444549, -0.08569903,\n",
       "           -0.04302965, -0.06467969,  0.01484227,  0.11647715,\n",
       "            0.06242896,  0.12979928, -0.06627296, -0.03289336,\n",
       "           -0.04412264, -0.14210472,  0.02482983,  0.11816369,\n",
       "           -0.03901243, -0.06461903,  0.02013189, -0.021237  ,\n",
       "           -0.04480952, -0.03188929,  0.00242625,  0.12643237]],\n",
       " \n",
       "         [[ 0.11918304, -0.12869054, -0.08481231, -0.04497596,\n",
       "            0.11013904,  0.0506993 , -0.09284461,  0.02525095,\n",
       "            0.05088448,  0.06942602,  0.02868193,  0.01191038,\n",
       "            0.06470225,  0.10284705, -0.12178671, -0.07650281,\n",
       "            0.04656651, -0.10060395,  0.13413689, -0.131673  ,\n",
       "           -0.10457101,  0.06575863, -0.09616413, -0.05517131,\n",
       "           -0.02092821,  0.1254442 ,  0.14117262, -0.03405815,\n",
       "            0.11438625, -0.04261739,  0.13142885, -0.11797609]]],\n",
       " \n",
       " \n",
       "        [[[-0.07381047, -0.08221164,  0.02982936,  0.00191712,\n",
       "            0.03497742,  0.12627664, -0.11473048,  0.11461858,\n",
       "            0.07839392,  0.03097065,  0.08147401, -0.13502884,\n",
       "            0.08110422, -0.05701615,  0.09691734, -0.11065044,\n",
       "           -0.01830165,  0.03986258,  0.11720821, -0.08759144,\n",
       "           -0.14064907, -0.02329334,  0.11788872, -0.10126577,\n",
       "            0.11926275, -0.05564029,  0.0389412 ,  0.04252103,\n",
       "           -0.10714611,  0.00284055, -0.05854763,  0.06089899]],\n",
       " \n",
       "         [[-0.10668955, -0.00757417, -0.13488263, -0.01387001,\n",
       "            0.01584808,  0.07119035,  0.03672639, -0.04963328,\n",
       "           -0.10555474, -0.09664291,  0.12669821,  0.12931624,\n",
       "           -0.03106811,  0.10138319,  0.12495137,  0.02713143,\n",
       "           -0.05537092,  0.01905986,  0.00269733,  0.07627895,\n",
       "           -0.11204337, -0.0138684 ,  0.08022149, -0.05947936,\n",
       "           -0.07810038,  0.0475788 , -0.12722589,  0.09958844,\n",
       "           -0.08394446, -0.09489557,  0.12709504,  0.00747833]],\n",
       " \n",
       "         [[ 0.10064112,  0.1106846 ,  0.04239635,  0.07438073,\n",
       "           -0.12622069, -0.00255708, -0.07399037,  0.01597489,\n",
       "           -0.13433939, -0.11518735,  0.05067871,  0.13802132,\n",
       "            0.08378775,  0.07319105, -0.04219726, -0.130982  ,\n",
       "           -0.02611107,  0.0079241 , -0.13422734,  0.05095265,\n",
       "            0.01039593, -0.1063354 ,  0.01672681, -0.06268249,\n",
       "           -0.03129962,  0.05121721, -0.06544799,  0.13717115,\n",
       "           -0.0421814 ,  0.13817194,  0.08755849,  0.00326604]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_3/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([ 0.00600129,  0.01257125, -0.00496302, -0.0060029 ,  0.00600369,\n",
       "         0.01307364, -0.00599578, -0.00600371,  0.0126903 ,  0.00599927,\n",
       "        -0.0060035 , -0.00600285,  0.01280483,  0.0060036 , -0.00600322,\n",
       "        -0.00602904,  0.01265054,  0.00597941,  0.00600271,  0.01292599,\n",
       "         0.0127635 ,  0.00599914,  0.0129887 , -0.00594924,  0.00599887,\n",
       "         0.01275559, -0.00323115, -0.00754611, -0.006003  , -0.0059995 ,\n",
       "         0.01277578,  0.00600268], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 16, 64) dtype=float32, numpy=\n",
       " array([[[[-0.05442693, -0.05178376, -0.04415904, ..., -0.02234921,\n",
       "           -0.03283736, -0.06380785],\n",
       "          [-0.0741675 , -0.08412673, -0.00621558, ..., -0.0091862 ,\n",
       "            0.04429675, -0.02614496],\n",
       "          [ 0.06119763, -0.08992548, -0.07807603, ..., -0.07656965,\n",
       "           -0.02614084, -0.09105296],\n",
       "          ...,\n",
       "          [-0.05014598, -0.05928517,  0.08790949, ...,  0.07739037,\n",
       "            0.0551841 , -0.03413028],\n",
       "          [ 0.02046059,  0.08018574,  0.01062438, ...,  0.02103243,\n",
       "           -0.03652661, -0.0666087 ],\n",
       "          [ 0.01422634,  0.05700187, -0.00439347, ...,  0.04069995,\n",
       "           -0.0588046 ,  0.08007952]],\n",
       " \n",
       "         [[ 0.05398648,  0.06972586, -0.00970365, ...,  0.08880524,\n",
       "           -0.07612716,  0.06540098],\n",
       "          [ 0.01006677, -0.01451088,  0.01925187, ..., -0.01053956,\n",
       "            0.00746352, -0.03140761],\n",
       "          [ 0.01298517,  0.03544986,  0.00263328, ...,  0.02387011,\n",
       "           -0.02038001,  0.01619245],\n",
       "          ...,\n",
       "          [ 0.08152586, -0.06462993,  0.08686262, ...,  0.03959181,\n",
       "            0.07465769, -0.02081821],\n",
       "          [ 0.0726338 , -0.02891484,  0.01930459, ..., -0.03326888,\n",
       "            0.03496187, -0.00326207],\n",
       "          [-0.01147633, -0.04482141, -0.00593822, ...,  0.08050606,\n",
       "           -0.02799722, -0.02353402]],\n",
       " \n",
       "         [[-0.01545228, -0.08477566, -0.02893312, ..., -0.00094698,\n",
       "            0.03356692,  0.07354687],\n",
       "          [-0.07856759, -0.06890851, -0.04758956, ..., -0.06220164,\n",
       "            0.03894595,  0.02947006],\n",
       "          [ 0.04617273, -0.0597664 , -0.0381532 , ..., -0.05819814,\n",
       "           -0.0938031 , -0.03685564],\n",
       "          ...,\n",
       "          [ 0.07853591, -0.06396959,  0.04080226, ..., -0.06408748,\n",
       "           -0.04108351, -0.01699278],\n",
       "          [ 0.06996296,  0.06177516, -0.08241784, ..., -0.09072299,\n",
       "           -0.01207959,  0.02421177],\n",
       "          [ 0.03937463, -0.06527673,  0.04193068, ..., -0.06682265,\n",
       "            0.07625477,  0.01723931]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0256795 , -0.02147181,  0.03733126, ..., -0.01982051,\n",
       "           -0.04167196,  0.06038506],\n",
       "          [ 0.00794936, -0.07348783,  0.08956562, ...,  0.00549669,\n",
       "           -0.04074649, -0.04927813],\n",
       "          [ 0.07801487,  0.01700696, -0.007445  , ...,  0.04758804,\n",
       "            0.05534305, -0.06708995],\n",
       "          ...,\n",
       "          [ 0.00101528, -0.00136692, -0.01851811, ..., -0.07390751,\n",
       "           -0.05093386,  0.081746  ],\n",
       "          [-0.00842458,  0.0885912 ,  0.04003951, ...,  0.07872429,\n",
       "           -0.03498121,  0.04865595],\n",
       "          [ 0.09452257,  0.08437246,  0.05349997, ..., -0.01678122,\n",
       "           -0.0001954 ,  0.01033853]],\n",
       " \n",
       "         [[ 0.02749423,  0.02773758,  0.02275877, ..., -0.06481625,\n",
       "            0.01074323, -0.02021543],\n",
       "          [-0.03986207, -0.03863151, -0.06451146, ...,  0.02647634,\n",
       "           -0.01576086, -0.08416348],\n",
       "          [ 0.05489418, -0.07825882,  0.0185047 , ..., -0.02867484,\n",
       "           -0.03819895,  0.09011094],\n",
       "          ...,\n",
       "          [ 0.01927395, -0.0705178 ,  0.04417113, ...,  0.06058321,\n",
       "           -0.02771161, -0.07450402],\n",
       "          [-0.08905889,  0.03613243, -0.05564112, ...,  0.01483862,\n",
       "            0.05749905, -0.02984704],\n",
       "          [-0.06170036, -0.04660489, -0.03361149, ..., -0.06306794,\n",
       "           -0.05400005, -0.00076986]],\n",
       " \n",
       "         [[-0.02151112, -0.07570042, -0.06316741, ..., -0.0232649 ,\n",
       "           -0.06946947, -0.06496643],\n",
       "          [-0.01622286, -0.02715699, -0.08841818, ...,  0.00523485,\n",
       "            0.0513588 , -0.03115779],\n",
       "          [ 0.00707179, -0.02571382, -0.0605635 , ..., -0.03390243,\n",
       "           -0.04443802,  0.01227059],\n",
       "          ...,\n",
       "          [ 0.00129769, -0.06338343,  0.06143805, ..., -0.03981359,\n",
       "           -0.01216285,  0.03116221],\n",
       "          [-0.0383791 , -0.0725148 , -0.00911383, ..., -0.06687643,\n",
       "            0.03144964, -0.02201404],\n",
       "          [ 0.09772328, -0.09019867,  0.03043496, ...,  0.01930549,\n",
       "           -0.06086992,  0.02301133]]],\n",
       " \n",
       " \n",
       "        [[[ 0.09091125,  0.07621275, -0.0305122 , ...,  0.07972224,\n",
       "            0.08244175,  0.01677296],\n",
       "          [-0.02543635, -0.04664343, -0.08243433, ..., -0.06276283,\n",
       "            0.00019053, -0.00543858],\n",
       "          [-0.02885505,  0.02556602, -0.07547045, ..., -0.08677104,\n",
       "            0.02455996,  0.00698507],\n",
       "          ...,\n",
       "          [ 0.03882845,  0.05284718,  0.00590216, ..., -0.023683  ,\n",
       "            0.08576869, -0.05184217],\n",
       "          [ 0.09033419, -0.0801201 ,  0.07846604, ..., -0.02469067,\n",
       "           -0.02118734,  0.01927084],\n",
       "          [ 0.0094944 ,  0.04987128,  0.02603907, ...,  0.08598949,\n",
       "            0.00696542,  0.08893723]],\n",
       " \n",
       "         [[-0.02964602,  0.06608546, -0.00852092, ...,  0.05478424,\n",
       "            0.03997926,  0.01402369],\n",
       "          [ 0.03082013, -0.00749416,  0.02694271, ..., -0.07740304,\n",
       "           -0.06605393, -0.06444466],\n",
       "          [-0.07911947,  0.07560743, -0.00897512, ...,  0.02052368,\n",
       "            0.03988839, -0.07136861],\n",
       "          ...,\n",
       "          [ 0.05423362, -0.02805877, -0.03900963, ...,  0.08067004,\n",
       "           -0.02054426, -0.02237979],\n",
       "          [ 0.00309296,  0.07091224, -0.0155511 , ...,  0.00359854,\n",
       "           -0.01524293,  0.03293301],\n",
       "          [ 0.02356336,  0.01593924, -0.05720962, ..., -0.01850779,\n",
       "           -0.08274265,  0.08036119]],\n",
       " \n",
       "         [[ 0.07499227,  0.0723965 , -0.0267828 , ...,  0.0014264 ,\n",
       "           -0.06749368, -0.07373247],\n",
       "          [ 0.03590729, -0.03078925, -0.05918564, ...,  0.07571546,\n",
       "           -0.07327989,  0.00013247],\n",
       "          [ 0.03526505, -0.08551518, -0.04213725, ...,  0.03348675,\n",
       "            0.01574321, -0.04933302],\n",
       "          ...,\n",
       "          [ 0.00648678, -0.05881067,  0.07855374, ..., -0.0245196 ,\n",
       "           -0.00621979, -0.00260349],\n",
       "          [-0.01290679, -0.03922473, -0.05184823, ...,  0.00354975,\n",
       "            0.0557898 , -0.02719151],\n",
       "          [ 0.01385317, -0.03305641, -0.08971952, ..., -0.03044126,\n",
       "            0.07713371,  0.02263334]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_4/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([ 0.01290653, -0.00592463,  0.00600246,  0.01283189,  0.01271111,\n",
       "        -0.00600309, -0.00600354, -0.00600362, -0.00600246, -0.00600385,\n",
       "        -0.00600383, -0.00600385,  0.01084313, -0.00516744, -0.00600348,\n",
       "         0.01116504,  0.0119856 , -0.00443692,  0.00600017,  0.0128025 ,\n",
       "        -0.00600381,  0.01264826,  0.0055093 , -0.00600386,  0.01283272,\n",
       "        -0.0059985 , -0.00600252, -0.00600291, -0.0060033 , -0.00600327,\n",
       "         0.01262846, -0.00600257, -0.0059994 ,  0.00897781, -0.00600383,\n",
       "        -0.00600364,  0.01275269,  0.00600095, -0.00357065, -0.00444673,\n",
       "         0.01287376, -0.00600214,  0.01258109,  0.00578532,  0.00600007,\n",
       "         0.01292703,  0.01272334, -0.00600276, -0.00598754,  0.0128953 ,\n",
       "        -0.00600217, -0.00600034, -0.00600117,  0.01292355,  0.01264842,\n",
       "         0.00600009, -0.00600305, -0.00600276,  0.00600374,  0.01279909,\n",
       "        -0.00600286, -0.00600372, -0.00431785, -0.00600388], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_5/kernel:0' shape=(3, 3, 32, 128) dtype=float32, numpy=\n",
       " array([[[[-8.83007329e-03, -1.01473294e-02, -4.73633632e-02, ...,\n",
       "            5.53936474e-02,  3.32148075e-02, -1.57776440e-03],\n",
       "          [-5.21327294e-02, -2.09297612e-02, -1.29895909e-02, ...,\n",
       "           -5.86919598e-02,  6.30391613e-02, -1.34964474e-02],\n",
       "          [-4.51629870e-02,  4.95996177e-02,  2.87699550e-02, ...,\n",
       "           -5.56864142e-02, -1.25882206e-02, -9.05115716e-03],\n",
       "          ...,\n",
       "          [ 1.18905231e-02,  9.48722288e-03, -1.09985878e-08, ...,\n",
       "           -3.14421952e-02, -5.30104572e-03,  2.23277602e-02],\n",
       "          [ 1.71107166e-02, -5.33014834e-02,  2.35905573e-02, ...,\n",
       "           -2.40305867e-02,  5.61219752e-02, -1.20962383e-02],\n",
       "          [-4.41148467e-02, -2.80980039e-02, -2.67693643e-02, ...,\n",
       "           -4.80538756e-02,  2.06323620e-02,  4.35920507e-02]],\n",
       " \n",
       "         [[ 6.11213706e-02,  5.76677658e-02, -6.16565198e-02, ...,\n",
       "           -2.31731776e-02,  1.76033434e-02, -5.46879098e-02],\n",
       "          [ 4.30810377e-02, -4.85094823e-03, -6.16279468e-02, ...,\n",
       "           -3.81236300e-02, -9.99226142e-03, -5.49226813e-02],\n",
       "          [ 4.11677770e-02, -5.52061573e-02, -2.09797602e-02, ...,\n",
       "            4.88158762e-02,  4.62795049e-02,  2.49534529e-02],\n",
       "          ...,\n",
       "          [-5.12864674e-03,  5.90982474e-02,  5.35049066e-02, ...,\n",
       "           -2.36725472e-02,  2.91604530e-02, -5.98278679e-02],\n",
       "          [ 2.01311382e-03, -9.10472963e-03,  6.98572304e-03, ...,\n",
       "            2.92094667e-02,  3.64302061e-02, -5.83431683e-02],\n",
       "          [ 5.41601256e-02, -6.74069533e-03,  1.96459983e-02, ...,\n",
       "           -3.55664119e-02, -2.79037766e-02,  1.80733390e-02]],\n",
       " \n",
       "         [[ 6.89856783e-02,  5.84653914e-02,  1.30377552e-02, ...,\n",
       "            7.59633072e-03, -3.50047238e-02, -2.54107136e-02],\n",
       "          [ 1.21259205e-02, -1.73281860e-02,  8.22806451e-03, ...,\n",
       "           -3.17205163e-03,  4.37386669e-02, -4.99132276e-02],\n",
       "          [ 4.43392284e-02, -5.51233627e-02, -5.60949976e-03, ...,\n",
       "           -6.08207546e-02,  1.27023375e-02,  1.03402622e-02],\n",
       "          ...,\n",
       "          [ 2.97137853e-02,  2.16169632e-03,  5.53043038e-02, ...,\n",
       "           -1.28876613e-02,  6.76199570e-02,  5.83468713e-02],\n",
       "          [-4.04733494e-02, -3.89853902e-02, -3.81604657e-02, ...,\n",
       "           -4.55932096e-02, -9.66432411e-03, -1.50270462e-02],\n",
       "          [-3.37324035e-03,  4.31975313e-02, -5.64320646e-02, ...,\n",
       "           -6.10790104e-02, -3.76553088e-02,  5.28589971e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 1.58179030e-02, -2.80268397e-02,  6.43652678e-02, ...,\n",
       "            4.10598889e-02,  1.05322981e-02, -3.20976577e-03],\n",
       "          [ 5.66161573e-02,  4.52333316e-02,  4.67139557e-02, ...,\n",
       "            2.21703239e-02,  9.22313519e-03, -5.02806678e-02],\n",
       "          [ 2.48484518e-02,  4.23342809e-02, -1.23873549e-02, ...,\n",
       "            5.36286794e-02,  2.08330117e-02, -4.70171757e-02],\n",
       "          ...,\n",
       "          [ 5.71786985e-02,  3.24620903e-02, -4.58661392e-02, ...,\n",
       "           -3.31105888e-02,  4.58656773e-02,  5.89562766e-03],\n",
       "          [-8.35366300e-05, -2.60686949e-02, -1.03339041e-02, ...,\n",
       "           -3.60974930e-02, -2.32020207e-02,  3.84721085e-02],\n",
       "          [-2.09581703e-02,  3.74414958e-02,  3.39971632e-02, ...,\n",
       "            5.18864207e-02, -4.63274606e-02,  4.93063740e-02]],\n",
       " \n",
       "         [[ 4.21043560e-02, -4.55461331e-02, -2.17716163e-03, ...,\n",
       "            6.31250516e-02,  6.08183406e-02, -3.60381566e-02],\n",
       "          [ 3.60127017e-02,  4.81604487e-02,  1.09751429e-02, ...,\n",
       "            5.77886105e-02,  4.43227142e-02, -5.05710915e-02],\n",
       "          [ 6.84061348e-02,  4.81960215e-02,  2.42769364e-02, ...,\n",
       "           -7.23533100e-03,  5.85797876e-02, -1.11272614e-02],\n",
       "          ...,\n",
       "          [ 3.85722220e-02, -4.71915957e-03,  5.47521189e-02, ...,\n",
       "            6.85554184e-03,  6.96976632e-02, -6.79703057e-03],\n",
       "          [ 6.16157949e-02,  1.41284214e-02, -1.35054975e-03, ...,\n",
       "            4.91892435e-02, -3.16053182e-02,  6.16842881e-02],\n",
       "          [-5.29319607e-02, -6.21591434e-02,  1.64785925e-02, ...,\n",
       "            5.53637594e-02, -2.06642486e-02, -7.95891043e-03]],\n",
       " \n",
       "         [[ 6.96720183e-02, -6.06596330e-03, -3.14163193e-02, ...,\n",
       "           -4.50254306e-02, -3.64032760e-02,  1.99673753e-02],\n",
       "          [-2.67599020e-02, -2.44994685e-02, -2.23101899e-02, ...,\n",
       "            3.12069859e-02,  6.83849351e-03, -3.03804893e-02],\n",
       "          [ 3.16188857e-02,  3.26055959e-02, -5.80432452e-02, ...,\n",
       "            1.05594359e-02, -3.62365022e-02,  1.26349535e-02],\n",
       "          ...,\n",
       "          [ 5.35972342e-02, -3.45871747e-02,  7.74989789e-03, ...,\n",
       "            2.66124550e-02, -2.58242805e-02, -4.23703063e-03],\n",
       "          [ 4.44524474e-02,  2.45267339e-02,  7.58413645e-03, ...,\n",
       "           -5.90475164e-02, -6.19764626e-03,  1.34787336e-02],\n",
       "          [-5.21111786e-02,  4.66233976e-02,  8.83047190e-03, ...,\n",
       "           -2.76974123e-02,  5.35827912e-02,  4.73110862e-02]]],\n",
       " \n",
       " \n",
       "        [[[-3.13728340e-02, -1.36461388e-02,  3.53938788e-02, ...,\n",
       "           -5.14542460e-02,  3.66486646e-02, -1.63842048e-02],\n",
       "          [-1.98667143e-02, -2.24388223e-02, -3.81802469e-02, ...,\n",
       "            5.12184612e-02,  4.61887866e-02,  6.02476746e-02],\n",
       "          [ 1.09757492e-02, -4.99276109e-02, -1.41757568e-02, ...,\n",
       "           -4.81939800e-02, -1.19198281e-02,  2.09190585e-02],\n",
       "          ...,\n",
       "          [-1.41965151e-02,  6.09509870e-02,  1.82814915e-02, ...,\n",
       "           -5.34582138e-02,  4.48604897e-02, -4.74053919e-02],\n",
       "          [-4.89205495e-02, -4.51667123e-02, -6.05880320e-02, ...,\n",
       "            3.29681672e-02,  4.20133546e-02,  5.90013266e-02],\n",
       "          [ 3.15278955e-02,  3.87570411e-02, -2.89411042e-02, ...,\n",
       "           -6.34085312e-02,  3.83141674e-02,  5.94665334e-02]],\n",
       " \n",
       "         [[ 3.07458602e-02, -6.29230291e-02,  1.50154252e-02, ...,\n",
       "            2.49055531e-02,  5.65097556e-02, -6.41607214e-03],\n",
       "          [ 5.24779744e-02,  2.78578140e-02,  5.34007438e-02, ...,\n",
       "            5.90809025e-02,  2.36022398e-02,  3.11883986e-02],\n",
       "          [-5.22642806e-02, -3.29513252e-02,  5.10933697e-02, ...,\n",
       "            5.88904582e-02, -2.79980376e-02,  3.88486460e-02],\n",
       "          ...,\n",
       "          [ 2.42628027e-02, -6.35472611e-02,  2.24487688e-02, ...,\n",
       "           -9.23481770e-03,  3.61498483e-02,  4.81281877e-02],\n",
       "          [ 5.49968220e-02, -5.01803532e-02,  3.36818807e-02, ...,\n",
       "            2.74833832e-02,  1.81534421e-02, -2.41853613e-02],\n",
       "          [ 5.75421751e-03,  4.68247384e-03, -5.52613139e-02, ...,\n",
       "           -1.16042104e-02, -5.44630177e-02, -5.21995686e-02]],\n",
       " \n",
       "         [[ 6.19629286e-02, -1.14981849e-02,  4.63532135e-02, ...,\n",
       "            3.22346054e-02,  3.84564847e-02,  5.74075840e-02],\n",
       "          [-3.93981766e-03,  3.51378135e-02, -5.83540350e-02, ...,\n",
       "            5.05301394e-02, -3.49153094e-02,  5.92816807e-02],\n",
       "          [-3.92356142e-02, -2.46160440e-02,  2.32976843e-02, ...,\n",
       "           -3.60117592e-02,  5.33808619e-02, -4.08402830e-03],\n",
       "          ...,\n",
       "          [ 5.67142032e-02,  6.38282821e-02,  7.09920842e-03, ...,\n",
       "           -1.20241055e-02,  1.86844300e-02, -8.25373270e-03],\n",
       "          [-3.24913785e-02,  2.27632970e-02, -1.54616525e-02, ...,\n",
       "            2.39244308e-02, -1.55489463e-02,  4.50270735e-02],\n",
       "          [-2.82008504e-03,  5.38603403e-03, -5.57908379e-02, ...,\n",
       "            4.05258983e-02, -2.21732594e-02, -1.18383695e-03]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_5/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([ 0.01317958,  0.00600196,  0.00600375,  0.0128059 , -0.00600377,\n",
       "        -0.00600394,  0.0126715 ,  0.00600029, -0.00600365,  0.01266441,\n",
       "        -0.00600184,  0.01287283,  0.00600014,  0.01126237,  0.01271674,\n",
       "         0.00600298, -0.00869689, -0.00598481,  0.00752743, -0.00599732,\n",
       "        -0.0027382 ,  0.00273073,  0.01100568, -0.00600389,  0.00371549,\n",
       "         0.01246089,  0.00600344,  0.01297901, -0.00600358, -0.00433864,\n",
       "         0.00276526, -0.00845156,  0.0060033 ,  0.01276942, -0.00600289,\n",
       "        -0.00357467, -0.00600337, -0.00600367, -0.00595943,  0.01260765,\n",
       "         0.00598485,  0.01293947,  0.005129  ,  0.00637568, -0.00600278,\n",
       "        -0.00600312, -0.00600254, -0.00600394, -0.0009045 ,  0.01246585,\n",
       "         0.00600249,  0.01286523, -0.00597474,  0.01286815, -0.00600348,\n",
       "        -0.00600373,  0.01271631,  0.00587596, -0.00600374, -0.00600282,\n",
       "        -0.00446554, -0.00600395,  0.01050417, -0.00599642,  0.01281894,\n",
       "         0.00600252,  0.01276296,  0.00600238, -0.00600116,  0.00953584,\n",
       "         0.00734341, -0.00600305,  0.00599689,  0.01281834,  0.01265382,\n",
       "        -0.00600318, -0.00375353, -0.00600329, -0.00600313, -0.00599104,\n",
       "         0.00599397,  0.01293284, -0.00600385, -0.00600345, -0.00600098,\n",
       "         0.01292848,  0.00600159, -0.00372155,  0.01282906,  0.00600332,\n",
       "        -0.00600316, -0.00600333, -0.00600378, -0.00599741, -0.00600208,\n",
       "         0.01279173, -0.00346669, -0.00600138, -0.00600068,  0.0122741 ,\n",
       "         0.00600388,  0.01295568,  0.01271505, -0.00600315,  0.01294725,\n",
       "         0.00600303, -0.00601107, -0.00600281,  0.01295094,  0.00600253,\n",
       "        -0.00600029,  0.0126788 , -0.00600236, -0.00600385,  0.00600323,\n",
       "         0.01281899, -0.00599912, -0.00600383,  0.01290292, -0.00600057,\n",
       "         0.        , -0.00600358,  0.01179403, -0.00600392,  0.01234244,\n",
       "        -0.00600086,  0.01273494,  0.00599497], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(1408, 10000) dtype=float32, numpy=\n",
       " array([[-0.00589907, -0.01026102,  0.03209437, ...,  0.02209509,\n",
       "          0.01105658, -0.00786022],\n",
       "        [ 0.03400715, -0.00073495,  0.0166896 , ...,  0.00358245,\n",
       "          0.01211868, -0.01031675],\n",
       "        [ 0.01003446,  0.00430901, -0.00792275, ...,  0.03232254,\n",
       "          0.01356869,  0.00630599],\n",
       "        ...,\n",
       "        [ 0.00091723,  0.0191725 ,  0.00323254, ...,  0.00795104,\n",
       "          0.01166158, -0.00862726],\n",
       "        [ 0.01875222,  0.03041126, -0.00129243, ...,  0.0201001 ,\n",
       "         -0.01639521,  0.01159186],\n",
       "        [-0.00402245, -0.00404792,  0.01659296, ..., -0.00182605,\n",
       "         -0.01990779,  0.00708315]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(10000,) dtype=float32, numpy=\n",
       " array([ 0.01444931,  0.01420959,  0.01386012, ...,  0.01416444,\n",
       "        -0.00534919,  0.01314625], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(10000, 3) dtype=float32, numpy=\n",
       " array([[ 0.02011253,  0.01135438, -0.02723164],\n",
       "        [ 0.02449715, -0.02732855, -0.00318958],\n",
       "        [ 0.02517318, -0.01694393,  0.00353451],\n",
       "        ...,\n",
       "        [ 0.00424048, -0.03542908, -0.03048948],\n",
       "        [-0.01562222, -0.01369943, -0.01597771],\n",
       "        [ 0.01580297, -0.0297045 , -0.03505971]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.01389398, -0.01387323, -0.01391417], dtype=float32)>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nteract": {
   "version": "nteract-on-jupyter@1.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
